{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "220c9622-46fc-406b-9ae2-7c1c2ac42784",
    "_uuid": "a1329a7a-aa97-402b-97ca-651a70fbddda",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:44.754731Z",
     "iopub.status.busy": "2021-06-18T16:27:44.754199Z",
     "iopub.status.idle": "2021-06-18T16:27:44.779537Z",
     "shell.execute_reply": "2021-06-18T16:27:44.780140Z",
     "shell.execute_reply.started": "2021-06-18T14:47:59.695484Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.049434,
     "end_time": "2021-06-18T16:27:44.780300",
     "exception": false,
     "start_time": "2021-06-18T16:27:44.730866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sample-xjtu/sic_6_1.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_4.npy\n",
      "/kaggle/input/sample-xjtu/dic_6_1.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_2.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_4.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_3.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_6.npy\n",
      "/kaggle/input/sample-xjtu/dic_1_1.npy\n",
      "/kaggle/input/sample-xjtu/sic_1_1.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_5.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_1.npy\n",
      "/kaggle/input/sample-xjtu/dic_3_6.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_1.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_2.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_3.npy\n",
      "/kaggle/input/sample-xjtu/sic_3_5.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015826,
     "end_time": "2021-06-18T16:27:44.812874",
     "exception": false,
     "start_time": "2021-06-18T16:27:44.797048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 import required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:44.850219Z",
     "iopub.status.busy": "2021-06-18T16:27:44.849715Z",
     "iopub.status.idle": "2021-06-18T16:27:51.174405Z",
     "shell.execute_reply": "2021-06-18T16:27:51.173899Z",
     "shell.execute_reply.started": "2021-06-18T14:47:59.722994Z"
    },
    "papermill": {
     "duration": 6.345724,
     "end_time": "2021-06-18T16:27:51.174505",
     "exception": false,
     "start_time": "2021-06-18T16:27:44.828781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:51.220292Z",
     "iopub.status.busy": "2021-06-18T16:27:51.218598Z",
     "iopub.status.idle": "2021-06-18T16:27:51.222382Z",
     "shell.execute_reply": "2021-06-18T16:27:51.221951Z",
     "shell.execute_reply.started": "2021-06-18T14:47:59.731313Z"
    },
    "papermill": {
     "duration": 0.03091,
     "end_time": "2021-06-18T16:27:51.222463",
     "exception": false,
     "start_time": "2021-06-18T16:27:51.191553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016475,
     "end_time": "2021-06-18T16:27:51.255901",
     "exception": false,
     "start_time": "2021-06-18T16:27:51.239426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 get the index and features name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:51.303352Z",
     "iopub.status.busy": "2021-06-18T16:27:51.301873Z",
     "iopub.status.idle": "2021-06-18T16:27:51.305823Z",
     "shell.execute_reply": "2021-06-18T16:27:51.305388Z",
     "shell.execute_reply.started": "2021-06-18T14:47:59.742978Z"
    },
    "papermill": {
     "duration": 0.033317,
     "end_time": "2021-06-18T16:27:51.305907",
     "exception": false,
     "start_time": "2021-06-18T16:27:51.272590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, \n",
    "         16, 19, 21, 22, 25, 27, 28, 29, 31, 32,\n",
    "         34, 35, 39, 40, 41, 42, 46, 48, 49, 50, \n",
    "         51, 53, 55, 56, 57, 58, 60, 61, 63, 64, \n",
    "         70, 73, 74, 75, 77, 78, 79, 80, 82, 83, \n",
    "         84, 85, 89, 91, 92, 98, 100, 102, 105, \n",
    "         106, 107, 110, 111, 115, 116, 117, 119, \n",
    "         120, 122, 124, 131, 133, 135, 136, 138, \n",
    "         140, 141, 144, 145, 146, 147, 150, 151, \n",
    "         152, 155, 157, 159, 160, 161, 162, 163, \n",
    "         164, 165, 166, 170, 171, 173]\n",
    "\n",
    "items = ['PLT', 'INR', 'D-Dimer', 'FIB', 'PT', 'HBA1c', 'HGB', \n",
    "         'Na', 'EO%', 'APOB', 'CK-MB', 'pO2', 'TBIL', 'Ca', \n",
    "         'TG', 'Cys-c', 'TP', 'CHOI', 'TCO2', 'gGlu', 'CO2CP', \n",
    "         'gHGB', 'PTA', 'NRBC%', 'ABE', 'MCV', 'CHE', 'Cl-', \n",
    "         'CaO2', 'PDW', 'Î±-HBDH', 'CRE', 'RDW-CV', 'WBC', \n",
    "         'P-LCR', 'GA%', 'K+', 'AMY', 'SOD', 'CK', 'TBA', \n",
    "         'MCH', 'UA', 'Mg', 'Lac', 'GLB', 'HDL', 'FCOHb', \n",
    "         'LDH', 'Glu', 'IG%', 'BUN', 'Cl', 'SpO2', 'PA-aDO2', \n",
    "         'FDP', 'p50', 'MetHb', 'APOA', 'DBIL', 'MCHC', 'ALB', \n",
    "         'RBC', 'eGFR', 'MPV', 'PA', 'Na+', 'pH', 'HCT', 'GGT', \n",
    "         'APOE', 'ALP', 'FO2Hb', 'AG', 'PCT', 'APTT', 'K', 'AB', \n",
    "         'LPS', 'proBNP', 'pCO2', 'ALT', 'A/G', 'LDL', 'Lp(a)', \n",
    "         'RDW-SD', 'MONO%', 'NEUT%', 'TnT', 'LYMPH%', 'BASO%', \n",
    "         'procalcitonin', 'P', 'HHb', 'AST', 'IDBIL', 'Ca2+', \n",
    "         'T', 'TT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016512,
     "end_time": "2021-06-18T16:27:51.339028",
     "exception": false,
     "start_time": "2021-06-18T16:27:51.322516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3 get the train, valid, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:51.378231Z",
     "iopub.status.busy": "2021-06-18T16:27:51.377740Z",
     "iopub.status.idle": "2021-06-18T16:27:59.038014Z",
     "shell.execute_reply": "2021-06-18T16:27:59.038897Z",
     "shell.execute_reply.started": "2021-06-18T14:47:59.761298Z"
    },
    "papermill": {
     "duration": 7.683176,
     "end_time": "2021-06-18T16:27:59.039061",
     "exception": false,
     "start_time": "2021-06-18T16:27:51.355885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7878\n"
     ]
    }
   ],
   "source": [
    "data = np.load('../input/sample-xjtu/dic_3_1.npy',allow_pickle = True)\n",
    "data1 = []\n",
    "for i in data:\n",
    "    if np.sum(i[3][:,index]) != 0:\n",
    "        x = torch.FloatTensor(i[2][:, index]).to(device)\n",
    "        y = torch.FloatTensor([i[-1]]).to(device)\n",
    "        data1.append((x, y))\n",
    "data = data1\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:59.089883Z",
     "iopub.status.busy": "2021-06-18T16:27:59.089354Z",
     "iopub.status.idle": "2021-06-18T16:27:59.784375Z",
     "shell.execute_reply": "2021-06-18T16:27:59.783931Z",
     "shell.execute_reply.started": "2021-06-18T14:48:00.932996Z"
    },
    "papermill": {
     "duration": 0.726839,
     "end_time": "2021-06-18T16:27:59.784474",
     "exception": false,
     "start_time": "2021-06-18T16:27:59.057635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_min_max(records):\n",
    "    data_min, data_max = None, None\n",
    "    inf = torch.Tensor([float(\"Inf\")])[0].to(device)\n",
    "    for b, (vals, labels) in enumerate(records):\n",
    "        \n",
    "        batch_min = torch.min(vals, dim = 0)[0]\n",
    "        batch_max = torch.max(vals, dim = 0)[0]\n",
    "        if (data_min is None) and (data_max is None):\n",
    "            data_min = batch_min\n",
    "            data_max = batch_max\n",
    "        else:\n",
    "            data_min = torch.min(data_min, batch_min)\n",
    "            data_max = torch.max(data_max, batch_max)\n",
    "    return data_min, data_max\n",
    "\n",
    "def data_norm(data):\n",
    "    data_new = []\n",
    "    data_min, data_max = get_data_min_max(data)\n",
    "    zero_index = torch.where(data_min==data_max)[0]\n",
    "    if zero_index.size(0) != 0:\n",
    "        data_max[zero_index] = 1\n",
    "    for (vals,label) in data:\n",
    "        data_new.append(((vals-data_min)/(data_max-data_min), label))\n",
    "    return data_new\n",
    "\n",
    "data = data_norm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:59.830415Z",
     "iopub.status.busy": "2021-06-18T16:27:59.829915Z",
     "iopub.status.idle": "2021-06-18T16:27:59.833754Z",
     "shell.execute_reply": "2021-06-18T16:27:59.833334Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.683832Z"
    },
    "papermill": {
     "duration": 0.03217,
     "end_time": "2021-06-18T16:27:59.833840",
     "exception": false,
     "start_time": "2021-06-18T16:27:59.801670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset,testset = model_selection.train_test_split(data,test_size = 0.2, random_state = 42, shuffle = True)\n",
    "trainset,validset = model_selection.train_test_split(trainset, test_size = 0.125, random_state = 42)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=50, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:27:59.873422Z",
     "iopub.status.busy": "2021-06-18T16:27:59.872554Z",
     "iopub.status.idle": "2021-06-18T16:28:00.050135Z",
     "shell.execute_reply": "2021-06-18T16:28:00.049541Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.711547Z"
    },
    "papermill": {
     "duration": 0.199413,
     "end_time": "2021-06-18T16:28:00.050254",
     "exception": false,
     "start_time": "2021-06-18T16:27:59.850841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: tensor([3051.], device='cuda:0') \t0: tensor([4827.], device='cuda:0') \ttotal: 7878\n",
      "1: tensor([2115.], device='cuda:0') \t0: tensor([3399.], device='cuda:0') \ttotal: 5514\n",
      "1: tensor([332.], device='cuda:0') \t0: tensor([456.], device='cuda:0') \ttotal: 788\n",
      "1: tensor([604.], device='cuda:0') \t0: tensor([972.], device='cuda:0') \ttotal: 1576\n"
     ]
    }
   ],
   "source": [
    "def check_label(data):\n",
    "    n = 0\n",
    "    for (i,j) in data:\n",
    "        n = n + j\n",
    "    print('1:',n,'\\t0:',len(data)-n,'\\ttotal:',len(data))\n",
    "\n",
    "check_label(data)\n",
    "check_label(trainset)\n",
    "check_label(validset)\n",
    "check_label(testset)\n",
    "auc_value = []\n",
    "result_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017034,
     "end_time": "2021-06-18T16:28:00.085899",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.068865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4 Define train and test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.131463Z",
     "iopub.status.busy": "2021-06-18T16:28:00.130818Z",
     "iopub.status.idle": "2021-06-18T16:28:00.133721Z",
     "shell.execute_reply": "2021-06-18T16:28:00.133312Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.888155Z"
    },
    "papermill": {
     "duration": 0.030494,
     "end_time": "2021-06-18T16:28:00.133805",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.103311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch, dataloader, name):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_all = torch.ones(0).to(device)\n",
    "    results = torch.ones(0).to(device)\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(torch.squeeze(inputs, 1))\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # _, predicted = outputs.max(1)\n",
    "        predicted = torch.round(outputs)\n",
    "        predicted_all = torch.cat((predicted_all,predicted))\n",
    "        results = torch.cat((results,targets))\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    model_auc = roc_auc_score(results.cpu().detach().numpy(),predicted_all.cpu().detach().numpy())\n",
    "    model_save(net, name, epoch)\n",
    "    print('train:',batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (train_loss/(batch_idx+1), 100.*correct/total, correct, total),model_auc)\n",
    "    return model_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.180318Z",
     "iopub.status.busy": "2021-06-18T16:28:00.179652Z",
     "iopub.status.idle": "2021-06-18T16:28:00.182620Z",
     "shell.execute_reply": "2021-06-18T16:28:00.182207Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.901977Z"
    },
    "papermill": {
     "duration": 0.03171,
     "end_time": "2021-06-18T16:28:00.182704",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.150994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(epoch, dataloader):\n",
    "    result =[]\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_all = torch.ones(0).to(device)\n",
    "    results = torch.ones(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            outputs = net(torch.squeeze(inputs, 1))\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            # _, predicted = outputs.max(1)\n",
    "            predicted = torch.round(outputs)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            predicted_all = torch.cat((predicted_all,outputs))\n",
    "            results = torch.cat((results,targets))\n",
    "        model_auc = roc_auc_score(results.cpu().detach().numpy(),predicted_all.cpu().detach().numpy())\n",
    "        print('test:',batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total), model_auc)\n",
    "        return model_auc,(results.cpu().detach().numpy().reshape(-1),predicted_all.cpu().detach().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.223628Z",
     "iopub.status.busy": "2021-06-18T16:28:00.222987Z",
     "iopub.status.idle": "2021-06-18T16:28:00.225901Z",
     "shell.execute_reply": "2021-06-18T16:28:00.225446Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.919602Z"
    },
    "papermill": {
     "duration": 0.025984,
     "end_time": "2021-06-18T16:28:00.225981",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.199997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_save(model, name, epoch):\n",
    "    if not os.path.exists('./' + name):\n",
    "        os.makedirs('./' + name)\n",
    "    torch.save(model, './' + name + '/' + str(epoch) + '.pt')\n",
    "\n",
    "def best_result(result):\n",
    "    best_index = np.where(result[:,0] == result[:,0].max())\n",
    "    print('best roc_auc on validset:', best_index[0][0], result[:,0].max())\n",
    "    return best_index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.264027Z",
     "iopub.status.busy": "2021-06-18T16:28:00.263337Z",
     "iopub.status.idle": "2021-06-18T16:28:00.266218Z",
     "shell.execute_reply": "2021-06-18T16:28:00.265816Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.931083Z"
    },
    "papermill": {
     "duration": 0.023053,
     "end_time": "2021-06-18T16:28:00.266298",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.243245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016998,
     "end_time": "2021-06-18T16:28:00.300329",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.283331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.342154Z",
     "iopub.status.busy": "2021-06-18T16:28:00.341429Z",
     "iopub.status.idle": "2021-06-18T16:28:00.344087Z",
     "shell.execute_reply": "2021-06-18T16:28:00.343693Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.941104Z"
    },
    "papermill": {
     "duration": 0.026377,
     "end_time": "2021-06-18T16:28:00.344168",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.317791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_layer, n_classes):\n",
    "        super(RNN,self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(in_dim, hidden_dim, n_layer, batch_first = True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(hidden_dim, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        out, h_n = self.rnn(x)\n",
    "        x = h_n[-1,:,:]\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:00.383325Z",
     "iopub.status.busy": "2021-06-18T16:28:00.382772Z",
     "iopub.status.idle": "2021-06-18T16:28:01.063122Z",
     "shell.execute_reply": "2021-06-18T16:28:01.063663Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.952731Z"
    },
    "papermill": {
     "duration": 0.702492,
     "end_time": "2021-06-18T16:28:01.063883",
     "exception": false,
     "start_time": "2021-06-18T16:28:00.361391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(99, 50, num_layers=2, batch_first=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = RNN(99, 50, 2, 1)\n",
    "net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:01.144959Z",
     "iopub.status.busy": "2021-06-18T16:28:01.144121Z",
     "iopub.status.idle": "2021-06-18T16:28:40.272202Z",
     "shell.execute_reply": "2021-06-18T16:28:40.272828Z",
     "shell.execute_reply.started": "2021-06-18T14:48:01.966221Z"
    },
    "papermill": {
     "duration": 39.171454,
     "end_time": "2021-06-18T16:28:40.272990",
     "exception": false,
     "start_time": "2021-06-18T16:28:01.101536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 110 111 Loss: 0.664 | Acc: 61.425% (3387/5514) 0.4990385157086251\n",
      "test: 15 32 Loss: 0.671 | Acc: 57.868% (456/788) 0.7361881737476221\n",
      "\n",
      "Epoch: 1\n",
      "train: 110 111 Loss: 0.633 | Acc: 64.436% (3553/5514) 0.5481948174160527\n",
      "test: 15 32 Loss: 0.607 | Acc: 68.020% (536/788) 0.756096755442824\n",
      "\n",
      "Epoch: 2\n",
      "train: 110 111 Loss: 0.580 | Acc: 69.568% (3836/5514) 0.63938872300781\n",
      "test: 15 32 Loss: 0.547 | Acc: 72.843% (574/788) 0.8160206615937434\n",
      "\n",
      "Epoch: 3\n",
      "train: 110 111 Loss: 0.532 | Acc: 73.540% (4055/5514) 0.6949125629356987\n",
      "test: 15 32 Loss: 0.490 | Acc: 78.934% (622/788) 0.8626215387867259\n",
      "\n",
      "Epoch: 4\n",
      "train: 110 111 Loss: 0.500 | Acc: 75.861% (4183/5514) 0.7240116513200587\n",
      "test: 15 32 Loss: 0.519 | Acc: 75.381% (594/788) 0.8820016909744239\n",
      "\n",
      "Epoch: 5\n",
      "train: 110 111 Loss: 0.494 | Acc: 76.260% (4205/5514) 0.732338255515285\n",
      "test: 15 32 Loss: 0.456 | Acc: 79.442% (626/788) 0.8858526210103572\n",
      "\n",
      "Epoch: 6\n",
      "train: 110 111 Loss: 0.453 | Acc: 78.981% (4355/5514) 0.7603869723886251\n",
      "test: 15 32 Loss: 0.425 | Acc: 80.457% (634/788) 0.8942414394419784\n",
      "\n",
      "Epoch: 7\n",
      "train: 110 111 Loss: 0.445 | Acc: 79.670% (4393/5514) 0.7712458190665173\n",
      "test: 15 32 Loss: 0.411 | Acc: 80.330% (633/788) 0.8938385119425067\n",
      "\n",
      "Epoch: 8\n",
      "train: 110 111 Loss: 0.457 | Acc: 78.110% (4307/5514) 0.7518971996352704\n",
      "test: 15 32 Loss: 0.464 | Acc: 77.919% (614/788) 0.8974450433312195\n",
      "\n",
      "Epoch: 9\n",
      "train: 110 111 Loss: 0.453 | Acc: 78.872% (4349/5514) 0.7625407138937401\n",
      "test: 15 32 Loss: 0.410 | Acc: 81.218% (640/788) 0.9014809236947791\n",
      "\n",
      "Epoch: 10\n",
      "train: 110 111 Loss: 0.431 | Acc: 80.250% (4425/5514) 0.7761316949707777\n",
      "test: 15 32 Loss: 0.418 | Acc: 81.472% (642/788) 0.9019961424645953\n",
      "\n",
      "Epoch: 11\n",
      "train: 110 111 Loss: 0.426 | Acc: 80.559% (4442/5514) 0.7806864346835427\n",
      "test: 15 32 Loss: 0.650 | Acc: 70.178% (553/788) 0.8955426971042062\n",
      "\n",
      "Epoch: 12\n",
      "train: 110 111 Loss: 0.418 | Acc: 81.592% (4499/5514) 0.7906787352976157\n",
      "test: 15 32 Loss: 0.390 | Acc: 82.360% (649/788) 0.9082646374973579\n",
      "\n",
      "Epoch: 13\n",
      "train: 110 111 Loss: 0.401 | Acc: 81.810% (4511/5514) 0.7937835283218468\n",
      "test: 15 32 Loss: 0.408 | Acc: 82.868% (653/788) 0.9077031811456352\n",
      "\n",
      "Epoch: 14\n",
      "train: 110 111 Loss: 0.426 | Acc: 80.613% (4445/5514) 0.783271049682948\n",
      "test: 15 32 Loss: 0.400 | Acc: 82.107% (647/788) 0.908066476432044\n",
      "\n",
      "Epoch: 15\n",
      "train: 110 111 Loss: 0.409 | Acc: 81.774% (4509/5514) 0.7953647192853968\n",
      "test: 15 32 Loss: 0.433 | Acc: 77.538% (611/788) 0.9079740012682309\n",
      "\n",
      "Epoch: 16\n",
      "train: 110 111 Loss: 0.399 | Acc: 82.173% (4531/5514) 0.7990474878927678\n",
      "test: 15 32 Loss: 0.387 | Acc: 83.249% (656/788) 0.9119834601564152\n",
      "\n",
      "Epoch: 17\n",
      "train: 110 111 Loss: 0.390 | Acc: 82.608% (4555/5514) 0.8048998558190874\n",
      "test: 15 32 Loss: 0.402 | Acc: 82.741% (652/788) 0.9085552737264849\n",
      "\n",
      "Epoch: 18\n",
      "train: 110 111 Loss: 0.393 | Acc: 82.644% (4557/5514) 0.8047475373441083\n",
      "test: 15 32 Loss: 0.420 | Acc: 79.061% (623/788) 0.9101603783555273\n",
      "\n",
      "Epoch: 19\n",
      "train: 110 111 Loss: 0.388 | Acc: 82.554% (4552/5514) 0.80401202689986\n",
      "test: 15 32 Loss: 0.387 | Acc: 83.249% (656/788) 0.9153786197421264\n",
      "\n",
      "Epoch: 20\n",
      "train: 110 111 Loss: 0.386 | Acc: 82.408% (4544/5514) 0.8039068645554909\n",
      "test: 15 32 Loss: 0.373 | Acc: 83.376% (657/788) 0.9136480131050517\n",
      "\n",
      "Epoch: 21\n",
      "train: 110 111 Loss: 0.390 | Acc: 82.789% (4565/5514) 0.8071746174824052\n",
      "test: 15 32 Loss: 0.379 | Acc: 85.279% (672/788) 0.910074508560558\n",
      "\n",
      "Epoch: 22\n",
      "train: 110 111 Loss: 0.382 | Acc: 83.170% (4586/5514) 0.8111568066536049\n",
      "test: 15 32 Loss: 0.367 | Acc: 84.137% (663/788) 0.9145067110547453\n",
      "\n",
      "Epoch: 23\n",
      "train: 110 111 Loss: 0.378 | Acc: 83.061% (4580/5514) 0.8116137620785422\n",
      "test: 15 32 Loss: 0.389 | Acc: 83.376% (657/788) 0.9133705876136123\n",
      "\n",
      "Epoch: 24\n",
      "train: 110 111 Loss: 0.376 | Acc: 83.333% (4595/5514) 0.8134630752891443\n",
      "test: 15 32 Loss: 0.489 | Acc: 76.777% (605/788) 0.9078484992601985\n",
      "\n",
      "Epoch: 25\n",
      "train: 110 111 Loss: 0.382 | Acc: 83.116% (4583/5514) 0.8116085456924127\n",
      "test: 15 32 Loss: 0.378 | Acc: 85.152% (671/788) 0.9120363031071655\n",
      "\n",
      "Epoch: 26\n",
      "train: 110 111 Loss: 0.374 | Acc: 83.714% (4616/5514) 0.8193206596015934\n",
      "test: 15 32 Loss: 0.367 | Acc: 85.025% (670/788) 0.9149558761361235\n",
      "\n",
      "Epoch: 27\n",
      "train: 110 111 Loss: 0.368 | Acc: 83.986% (4631/5514) 0.8217057999954095\n",
      "test: 15 32 Loss: 0.394 | Acc: 83.376% (657/788) 0.9168648277319804\n",
      "\n",
      "Epoch: 28\n",
      "train: 110 111 Loss: 0.375 | Acc: 83.605% (4610/5514) 0.8187059606601024\n",
      "test: 15 32 Loss: 0.547 | Acc: 75.254% (593/788) 0.912571337983513\n",
      "\n",
      "Epoch: 29\n",
      "train: 110 111 Loss: 0.383 | Acc: 83.261% (4591/5514) 0.8146607575444592\n",
      "test: 15 32 Loss: 0.410 | Acc: 81.091% (639/788) 0.9166336398224477\n",
      "\n",
      "Epoch: 30\n",
      "train: 110 111 Loss: 0.363 | Acc: 84.240% (4645/5514) 0.8242117518919834\n",
      "test: 15 32 Loss: 0.381 | Acc: 83.376% (657/788) 0.9176046290424857\n",
      "\n",
      "Epoch: 31\n",
      "train: 110 111 Loss: 0.372 | Acc: 83.642% (4612/5514) 0.8184643376545876\n",
      "test: 15 32 Loss: 0.425 | Acc: 80.203% (632/788) 0.9143613929401818\n",
      "\n",
      "Epoch: 32\n",
      "train: 110 111 Loss: 0.370 | Acc: 83.424% (4600/5514) 0.8160739808746418\n",
      "test: 15 32 Loss: 0.427 | Acc: 80.330% (633/788) 0.9193814732614668\n",
      "\n",
      "Epoch: 33\n",
      "train: 110 111 Loss: 0.373 | Acc: 82.644% (4557/5514) 0.8075159777907145\n",
      "test: 15 32 Loss: 0.360 | Acc: 84.645% (667/788) 0.9185293806806172\n",
      "\n",
      "Epoch: 34\n",
      "train: 110 111 Loss: 0.365 | Acc: 84.149% (4640/5514) 0.824012068630949\n",
      "test: 15 32 Loss: 0.360 | Acc: 85.533% (674/788) 0.9196721094905941\n",
      "\n",
      "Epoch: 35\n",
      "train: 110 111 Loss: 0.361 | Acc: 84.168% (4641/5514) 0.8250522160251554\n",
      "test: 15 32 Loss: 0.360 | Acc: 84.645% (667/788) 0.9193946839991545\n",
      "\n",
      "Epoch: 36\n",
      "train: 110 111 Loss: 0.378 | Acc: 83.243% (4590/5514) 0.8141564373334669\n",
      "test: 15 32 Loss: 0.358 | Acc: 84.898% (669/788) 0.9188332276474318\n",
      "\n",
      "Epoch: 37\n",
      "train: 110 111 Loss: 0.383 | Acc: 82.916% (4572/5514) 0.8105262498982805\n",
      "test: 15 32 Loss: 0.367 | Acc: 84.898% (669/788) 0.9140047030226167\n",
      "\n",
      "Epoch: 38\n",
      "train: 110 111 Loss: 0.369 | Acc: 83.551% (4607/5514) 0.8187111770462319\n",
      "test: 15 32 Loss: 0.366 | Acc: 84.391% (665/788) 0.9171422532234199\n",
      "\n",
      "Epoch: 39\n",
      "train: 110 111 Loss: 0.365 | Acc: 84.113% (4638/5514) 0.8242536916364638\n",
      "test: 15 32 Loss: 0.366 | Acc: 85.406% (673/788) 0.9198108222363136\n",
      "\n",
      "Epoch: 40\n",
      "train: 110 111 Loss: 0.369 | Acc: 83.333% (4595/5514) 0.8158742976136076\n",
      "test: 15 32 Loss: 0.395 | Acc: 82.868% (653/788) 0.9219575671105474\n",
      "\n",
      "Epoch: 41\n",
      "train: 110 111 Loss: 0.355 | Acc: 84.621% (4666/5514) 0.8314982086930031\n",
      "test: 15 32 Loss: 0.382 | Acc: 82.995% (654/788) 0.9229681885436483\n",
      "\n",
      "Epoch: 42\n",
      "train: 110 111 Loss: 0.364 | Acc: 83.877% (4625/5514) 0.8221627554203469\n",
      "test: 15 32 Loss: 0.382 | Acc: 84.772% (668/788) 0.9188431357006975\n",
      "\n",
      "Epoch: 43\n",
      "train: 110 111 Loss: 0.356 | Acc: 84.276% (4647/5514) 0.825220392313968\n",
      "test: 15 32 Loss: 0.404 | Acc: 81.599% (643/788) 0.9211847389558233\n",
      "\n",
      "Epoch: 44\n",
      "train: 110 111 Loss: 0.362 | Acc: 84.186% (4642/5514) 0.8250207090529338\n",
      "test: 15 32 Loss: 0.388 | Acc: 82.614% (651/788) 0.9167723525681675\n",
      "\n",
      "Epoch: 45\n",
      "train: 110 111 Loss: 0.349 | Acc: 85.002% (4687/5514) 0.8328905664786681\n",
      "test: 15 32 Loss: 0.358 | Acc: 84.898% (669/788) 0.9219311456351723\n",
      "\n",
      "Epoch: 46\n",
      "train: 110 111 Loss: 0.356 | Acc: 84.476% (4658/5514) 0.8277315605966711\n",
      "test: 15 32 Loss: 0.359 | Acc: 85.025% (670/788) 0.9223208623969563\n",
      "\n",
      "Epoch: 47\n",
      "train: 110 111 Loss: 0.352 | Acc: 84.458% (4657/5514) 0.8280309811604998\n",
      "test: 15 32 Loss: 0.359 | Acc: 85.025% (670/788) 0.9204845698583809\n",
      "\n",
      "Epoch: 48\n",
      "train: 110 111 Loss: 0.348 | Acc: 84.947% (4684/5514) 0.834146046292297\n",
      "test: 15 32 Loss: 0.364 | Acc: 85.406% (673/788) 0.9220632530120482\n",
      "\n",
      "Epoch: 49\n",
      "train: 110 111 Loss: 0.344 | Acc: 84.984% (4686/5514) 0.8356012093669603\n",
      "test: 15 32 Loss: 0.386 | Acc: 84.010% (662/788) 0.920544018177975\n",
      "\n",
      "Epoch: 50\n",
      "train: 110 111 Loss: 0.364 | Acc: 83.787% (4620/5514) 0.8204448951402059\n",
      "test: 15 32 Loss: 0.357 | Acc: 85.533% (674/788) 0.921290424857324\n",
      "\n",
      "Epoch: 51\n",
      "train: 110 111 Loss: 0.364 | Acc: 84.113% (4638/5514) 0.8247895188196779\n",
      "test: 15 32 Loss: 0.367 | Acc: 84.391% (665/788) 0.9220236207989854\n",
      "\n",
      "Epoch: 52\n",
      "train: 110 111 Loss: 0.354 | Acc: 84.494% (4659/5514) 0.8288610125214133\n",
      "test: 15 32 Loss: 0.364 | Acc: 85.025% (670/788) 0.9220764637497358\n",
      "\n",
      "Epoch: 53\n",
      "train: 110 111 Loss: 0.354 | Acc: 84.458% (4657/5514) 0.8287454174047852\n",
      "test: 15 32 Loss: 0.375 | Acc: 83.883% (661/788) 0.9223604946100191\n",
      "\n",
      "Epoch: 54\n",
      "train: 110 111 Loss: 0.338 | Acc: 85.292% (4703/5514) 0.8385484675300828\n",
      "test: 15 32 Loss: 0.385 | Acc: 83.629% (659/788) 0.9184633269921791\n",
      "\n",
      "Epoch: 55\n",
      "train: 110 111 Loss: 0.335 | Acc: 85.111% (4693/5514) 0.8373453602331933\n",
      "test: 15 32 Loss: 0.355 | Acc: 84.264% (664/788) 0.9206827309236948\n",
      "\n",
      "Epoch: 56\n",
      "train: 110 111 Loss: 0.347 | Acc: 84.639% (4667/5514) 0.8309308745375673\n",
      "test: 15 32 Loss: 0.350 | Acc: 84.772% (668/788) 0.9231201120270556\n",
      "\n",
      "Epoch: 57\n",
      "train: 110 111 Loss: 0.340 | Acc: 85.074% (4691/5514) 0.8358008926279945\n",
      "test: 15 32 Loss: 0.377 | Acc: 84.391% (665/788) 0.9166072183470724\n",
      "\n",
      "Epoch: 58\n",
      "train: 110 111 Loss: 0.336 | Acc: 85.618% (4721/5514) 0.8411070005988412\n",
      "test: 15 32 Loss: 0.383 | Acc: 83.376% (657/788) 0.9206629148171634\n",
      "\n",
      "Epoch: 59\n",
      "train: 110 111 Loss: 0.354 | Acc: 84.240% (4645/5514) 0.8267122787469824\n",
      "test: 15 32 Loss: 0.389 | Acc: 82.868% (653/788) 0.9209733671528219\n",
      "\n",
      "Epoch: 60\n",
      "train: 110 111 Loss: 0.340 | Acc: 85.510% (4715/5514) 0.8409388243100286\n",
      "test: 15 32 Loss: 0.399 | Acc: 82.487% (650/788) 0.9238004650179666\n",
      "\n",
      "Epoch: 61\n",
      "train: 110 111 Loss: 0.336 | Acc: 85.238% (4700/5514) 0.8380178567329982\n",
      "test: 15 32 Loss: 0.446 | Acc: 80.584% (635/788) 0.9167657471993236\n",
      "\n",
      "Epoch: 62\n",
      "train: 110 111 Loss: 0.334 | Acc: 85.346% (4706/5514) 0.8389897737966319\n",
      "test: 15 32 Loss: 0.437 | Acc: 80.457% (634/788) 0.9203623705347707\n",
      "\n",
      "Epoch: 63\n",
      "train: 110 111 Loss: 0.328 | Acc: 85.745% (4728/5514) 0.843208369587217\n",
      "test: 15 32 Loss: 0.371 | Acc: 84.264% (664/788) 0.9217197738321709\n",
      "\n",
      "Epoch: 64\n",
      "train: 110 111 Loss: 0.342 | Acc: 85.256% (4701/5514) 0.8386114814745264\n",
      "test: 15 32 Loss: 0.348 | Acc: 86.168% (679/788) 0.925471623335447\n",
      "\n",
      "Epoch: 65\n",
      "train: 110 111 Loss: 0.338 | Acc: 85.274% (4702/5514) 0.8381334518496262\n",
      "test: 15 32 Loss: 0.357 | Acc: 85.533% (674/788) 0.9260661065313887\n",
      "\n",
      "Epoch: 66\n",
      "train: 110 111 Loss: 0.327 | Acc: 86.144% (4750/5514) 0.8479627925610161\n",
      "test: 15 32 Loss: 0.354 | Acc: 85.279% (672/788) 0.9222415979708307\n",
      "\n",
      "Epoch: 67\n",
      "train: 110 111 Loss: 0.337 | Acc: 85.419% (4710/5514) 0.8399354002741733\n",
      "test: 15 32 Loss: 0.366 | Acc: 84.645% (667/788) 0.9220566476432044\n",
      "\n",
      "Epoch: 68\n",
      "train: 110 111 Loss: 0.334 | Acc: 86.054% (4745/5514) 0.8475845002389106\n",
      "test: 15 32 Loss: 0.352 | Acc: 86.168% (679/788) 0.9216999577256394\n",
      "\n",
      "Epoch: 69\n",
      "train: 110 111 Loss: 0.329 | Acc: 85.673% (4724/5514) 0.8432450929455679\n",
      "test: 15 32 Loss: 0.363 | Acc: 84.137% (663/788) 0.9204185161699429\n",
      "\n",
      "Epoch: 70\n",
      "train: 110 111 Loss: 0.336 | Acc: 85.528% (4716/5514) 0.8413538399904853\n",
      "test: 15 32 Loss: 0.358 | Acc: 85.660% (675/788) 0.9253593320651026\n",
      "\n",
      "Epoch: 71\n",
      "train: 110 111 Loss: 0.330 | Acc: 85.745% (4728/5514) 0.8441907194231093\n",
      "test: 15 32 Loss: 0.388 | Acc: 83.756% (660/788) 0.921164922849292\n",
      "\n",
      "Epoch: 72\n",
      "train: 110 111 Loss: 0.320 | Acc: 86.253% (4756/5514) 0.8486667960330426\n",
      "test: 15 32 Loss: 0.384 | Acc: 84.264% (664/788) 0.9259273937856689\n",
      "\n",
      "Epoch: 73\n",
      "train: 110 111 Loss: 0.324 | Acc: 86.308% (4759/5514) 0.8496439294828059\n",
      "test: 15 32 Loss: 0.380 | Acc: 84.645% (667/788) 0.9240712851405621\n",
      "\n",
      "Epoch: 74\n",
      "train: 110 111 Loss: 0.321 | Acc: 86.398% (4764/5514) 0.8506473535186612\n",
      "test: 15 32 Loss: 0.386 | Acc: 83.756% (660/788) 0.9219839885859227\n",
      "\n",
      "Epoch: 75\n",
      "train: 110 111 Loss: 0.326 | Acc: 86.017% (4743/5514) 0.8478261232444252\n",
      "test: 15 32 Loss: 0.372 | Acc: 85.025% (670/788) 0.9233116677235257\n",
      "\n",
      "Epoch: 76\n",
      "train: 110 111 Loss: 0.323 | Acc: 86.072% (4746/5514) 0.8473743842056176\n",
      "test: 15 32 Loss: 0.365 | Acc: 84.772% (668/788) 0.9277240541111815\n",
      "\n",
      "Epoch: 77\n",
      "train: 110 111 Loss: 0.321 | Acc: 86.271% (4757/5514) 0.8497962479577849\n",
      "test: 15 32 Loss: 0.359 | Acc: 85.533% (674/788) 0.9260132635806384\n",
      "\n",
      "Epoch: 78\n",
      "train: 110 111 Loss: 0.317 | Acc: 86.235% (4755/5514) 0.8500378709632996\n",
      "test: 15 32 Loss: 0.450 | Acc: 80.584% (635/788) 0.9211913443246671\n",
      "\n",
      "Epoch: 79\n",
      "train: 110 111 Loss: 0.322 | Acc: 86.289% (4758/5514) 0.848425173027528\n",
      "test: 15 32 Loss: 0.456 | Acc: 79.822% (629/788) 0.9227502113718029\n",
      "\n",
      "Epoch: 80\n",
      "train: 110 111 Loss: 0.326 | Acc: 86.362% (4762/5514) 0.8501745402798905\n",
      "test: 15 32 Loss: 0.359 | Acc: 84.898% (669/788) 0.9203656732191925\n",
      "\n",
      "Epoch: 81\n",
      "train: 110 111 Loss: 0.320 | Acc: 86.344% (4761/5514) 0.849402306477291\n",
      "test: 15 32 Loss: 0.350 | Acc: 85.533% (674/788) 0.9252932783766645\n",
      "\n",
      "Epoch: 82\n",
      "train: 110 111 Loss: 0.334 | Acc: 85.002% (4687/5514) 0.8361055295779527\n",
      "test: 15 32 Loss: 0.441 | Acc: 81.853% (645/788) 0.9218518812090467\n",
      "\n",
      "Epoch: 83\n",
      "train: 110 111 Loss: 0.313 | Acc: 86.761% (4784/5514) 0.8538573088872614\n",
      "test: 15 32 Loss: 0.394 | Acc: 81.853% (645/788) 0.9243024730500952\n",
      "\n",
      "Epoch: 84\n",
      "train: 110 111 Loss: 0.315 | Acc: 86.308% (4759/5514) 0.8505369747881625\n",
      "test: 15 32 Loss: 0.349 | Acc: 86.421% (681/788) 0.9248176918199114\n",
      "\n",
      "Epoch: 85\n",
      "train: 110 111 Loss: 0.311 | Acc: 86.797% (4786/5514) 0.8556696900840672\n",
      "test: 15 32 Loss: 0.365 | Acc: 85.152% (671/788) 0.9236155146903404\n",
      "\n",
      "Epoch: 86\n",
      "train: 110 111 Loss: 0.313 | Acc: 86.634% (4777/5514) 0.8536313350401349\n",
      "test: 15 32 Loss: 0.350 | Acc: 85.787% (676/788) 0.9254187803846966\n",
      "\n",
      "Epoch: 87\n",
      "train: 110 111 Loss: 0.306 | Acc: 86.652% (4778/5514) 0.8546714824343414\n",
      "test: 15 32 Loss: 0.354 | Acc: 84.772% (668/788) 0.927162597759459\n",
      "\n",
      "Epoch: 88\n",
      "train: 110 111 Loss: 0.318 | Acc: 86.634% (4777/5514) 0.8518452444294213\n",
      "test: 15 32 Loss: 0.350 | Acc: 85.152% (671/788) 0.9244081589515958\n",
      "\n",
      "Epoch: 89\n",
      "train: 110 111 Loss: 0.310 | Acc: 86.997% (4797/5514) 0.8574664221224849\n",
      "test: 15 32 Loss: 0.374 | Acc: 84.391% (665/788) 0.9257490488268865\n",
      "\n",
      "Epoch: 90\n",
      "train: 110 111 Loss: 0.325 | Acc: 86.054% (4745/5514) 0.8467807594640894\n",
      "test: 15 32 Loss: 0.357 | Acc: 85.533% (674/788) 0.9233777214119637\n",
      "\n",
      "Epoch: 91\n",
      "train: 110 111 Loss: 0.305 | Acc: 87.051% (4800/5514) 0.8576398147974269\n",
      "test: 15 32 Loss: 0.356 | Acc: 85.025% (670/788) 0.9221425174381737\n",
      "\n",
      "Epoch: 92\n",
      "train: 110 111 Loss: 0.314 | Acc: 85.709% (4726/5514) 0.8439858197759457\n",
      "test: 15 32 Loss: 0.362 | Acc: 84.137% (663/788) 0.9216405094060452\n",
      "\n",
      "Epoch: 93\n",
      "train: 110 111 Loss: 0.311 | Acc: 86.507% (4770/5514) 0.8531374476014013\n",
      "test: 15 32 Loss: 0.365 | Acc: 84.645% (667/788) 0.9213762946522934\n",
      "\n",
      "Epoch: 94\n",
      "train: 110 111 Loss: 0.310 | Acc: 86.834% (4788/5514) 0.8557852852006952\n",
      "test: 15 32 Loss: 0.352 | Acc: 85.660% (675/788) 0.9265152716127669\n",
      "\n",
      "Epoch: 95\n",
      "train: 110 111 Loss: 0.298 | Acc: 87.287% (4813/5514) 0.8594628374219367\n",
      "test: 15 32 Loss: 0.348 | Acc: 85.533% (674/788) 0.9264822447685478\n",
      "\n",
      "Epoch: 96\n",
      "train: 110 111 Loss: 0.306 | Acc: 86.707% (4781/5514) 0.8550234841703547\n",
      "test: 15 32 Loss: 0.359 | Acc: 84.772% (668/788) 0.920193933629254\n",
      "\n",
      "Epoch: 97\n",
      "train: 110 111 Loss: 0.298 | Acc: 87.214% (4809/5514) 0.859231647188681\n",
      "test: 15 32 Loss: 0.413 | Acc: 83.249% (656/788) 0.9172149122807018\n",
      "\n",
      "Epoch: 98\n",
      "train: 110 111 Loss: 0.304 | Acc: 87.015% (4798/5514) 0.8573456106197275\n",
      "test: 15 32 Loss: 0.395 | Acc: 84.772% (668/788) 0.9150879835129994\n",
      "\n",
      "Epoch: 99\n",
      "train: 110 111 Loss: 0.308 | Acc: 86.815% (4787/5514) 0.853852092501132\n",
      "test: 15 32 Loss: 0.366 | Acc: 83.249% (656/788) 0.921779222151765\n",
      "cost time: 39.172500818\n",
      "best roc_auc on validset: 76 0.9277240541111815\n",
      "test: 31 32 Loss: 0.355 | Acc: 84.454% (1331/1576) 0.92383765295833\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "result_valid = []\n",
    "for epoch in range(100):\n",
    "    train(epoch, trainloader, 'RNN')\n",
    "    result_valid.append(np.array(test(epoch,validloader)))\n",
    "result_valid = np.array(result_valid)\n",
    "end = time.process_time()\n",
    "print('cost time:', end-start)\n",
    "\n",
    "best_index = best_result(result_valid)\n",
    "net = torch.load('./RNN/' + str(str(best_index)) +'.pt')\n",
    "torch.save(net, 'best_RNN.pt')\n",
    "auc, result_rnn = test(best_index,testloader)\n",
    "result['RNN'] = result_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045223,
     "end_time": "2021-06-18T16:28:40.364422",
     "exception": false,
     "start_time": "2021-06-18T16:28:40.319199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6 LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:40.463013Z",
     "iopub.status.busy": "2021-06-18T16:28:40.462339Z",
     "iopub.status.idle": "2021-06-18T16:28:40.465952Z",
     "shell.execute_reply": "2021-06-18T16:28:40.465457Z",
     "shell.execute_reply.started": "2021-06-18T14:49:06.241802Z"
    },
    "papermill": {
     "duration": 0.055914,
     "end_time": "2021-06-18T16:28:40.466054",
     "exception": false,
     "start_time": "2021-06-18T16:28:40.410140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_layer, n_classes):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim, n_layer, batch_first = True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(hidden_dim, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        x = h_n[-1, :, :]\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:40.562640Z",
     "iopub.status.busy": "2021-06-18T16:28:40.561805Z",
     "iopub.status.idle": "2021-06-18T16:28:40.569396Z",
     "shell.execute_reply": "2021-06-18T16:28:40.568821Z",
     "shell.execute_reply.started": "2021-06-18T14:49:06.253274Z"
    },
    "papermill": {
     "duration": 0.057953,
     "end_time": "2021-06-18T16:28:40.569510",
     "exception": false,
     "start_time": "2021-06-18T16:28:40.511557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(99, 50, num_layers=2, batch_first=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LSTM(99, 50, 2, 1)\n",
    "net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:28:40.669762Z",
     "iopub.status.busy": "2021-06-18T16:28:40.668987Z",
     "iopub.status.idle": "2021-06-18T16:29:21.031617Z",
     "shell.execute_reply": "2021-06-18T16:29:21.032192Z",
     "shell.execute_reply.started": "2021-06-18T14:49:06.268267Z"
    },
    "papermill": {
     "duration": 40.416879,
     "end_time": "2021-06-18T16:29:21.032366",
     "exception": false,
     "start_time": "2021-06-18T16:28:40.615487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 110 111 Loss: 0.673 | Acc: 58.778% (3241/5514) 0.5011380067979945\n",
      "test: 15 32 Loss: 0.685 | Acc: 57.868% (456/788) 0.518574297188755\n",
      "\n",
      "Epoch: 1\n",
      "train: 110 111 Loss: 0.665 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.684 | Acc: 57.868% (456/788) 0.5758395423800465\n",
      "\n",
      "Epoch: 2\n",
      "train: 110 111 Loss: 0.665 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.683 | Acc: 57.868% (456/788) 0.6319917829211583\n",
      "\n",
      "Epoch: 3\n",
      "train: 110 111 Loss: 0.666 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.682 | Acc: 57.868% (456/788) 0.6802109754808708\n",
      "\n",
      "Epoch: 4\n",
      "train: 110 111 Loss: 0.664 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.682 | Acc: 57.868% (456/788) 0.7040431462692877\n",
      "\n",
      "Epoch: 5\n",
      "train: 110 111 Loss: 0.665 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.682 | Acc: 57.868% (456/788) 0.7139842263792009\n",
      "\n",
      "Epoch: 6\n",
      "train: 110 111 Loss: 0.664 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.682 | Acc: 57.868% (456/788) 0.7173166349608964\n",
      "\n",
      "Epoch: 7\n",
      "train: 110 111 Loss: 0.664 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.681 | Acc: 57.868% (456/788) 0.7169929718875502\n",
      "\n",
      "Epoch: 8\n",
      "train: 110 111 Loss: 0.663 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.677 | Acc: 57.868% (456/788) 0.7154341048404143\n",
      "\n",
      "Epoch: 9\n",
      "train: 110 111 Loss: 0.662 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.676 | Acc: 57.868% (456/788) 0.7157775840202916\n",
      "\n",
      "Epoch: 10\n",
      "train: 110 111 Loss: 0.660 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.674 | Acc: 57.868% (456/788) 0.7164909638554217\n",
      "\n",
      "Epoch: 11\n",
      "train: 110 111 Loss: 0.659 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.672 | Acc: 57.868% (456/788) 0.7170458148383005\n",
      "\n",
      "Epoch: 12\n",
      "train: 110 111 Loss: 0.656 | Acc: 61.643% (3399/5514) 0.5\n",
      "test: 15 32 Loss: 0.667 | Acc: 57.868% (456/788) 0.7164579370112028\n",
      "\n",
      "Epoch: 13\n",
      "train: 110 111 Loss: 0.652 | Acc: 61.716% (3403/5514) 0.5009456264775414\n",
      "test: 15 32 Loss: 0.661 | Acc: 57.868% (456/788) 0.71822817586134\n",
      "\n",
      "Epoch: 14\n",
      "train: 110 111 Loss: 0.648 | Acc: 61.897% (3413/5514) 0.5039348243851445\n",
      "test: 15 32 Loss: 0.655 | Acc: 59.010% (465/788) 0.7209958254068907\n",
      "\n",
      "Epoch: 15\n",
      "train: 110 111 Loss: 0.641 | Acc: 63.330% (3492/5514) 0.5254686922937285\n",
      "test: 15 32 Loss: 0.645 | Acc: 60.787% (479/788) 0.7254841735362503\n",
      "\n",
      "Epoch: 16\n",
      "train: 110 111 Loss: 0.633 | Acc: 64.236% (3542/5514) 0.5433617313394219\n",
      "test: 15 32 Loss: 0.635 | Acc: 62.690% (494/788) 0.7338102409638554\n",
      "\n",
      "Epoch: 17\n",
      "train: 110 111 Loss: 0.622 | Acc: 65.905% (3634/5514) 0.5734164616626918\n",
      "test: 15 32 Loss: 0.617 | Acc: 67.893% (535/788) 0.7431634432466709\n",
      "\n",
      "Epoch: 18\n",
      "train: 110 111 Loss: 0.608 | Acc: 67.320% (3712/5514) 0.5975716679290322\n",
      "test: 15 32 Loss: 0.601 | Acc: 68.909% (543/788) 0.7594787042908476\n",
      "\n",
      "Epoch: 19\n",
      "train: 110 111 Loss: 0.589 | Acc: 69.115% (3811/5514) 0.6267807177330004\n",
      "test: 15 32 Loss: 0.580 | Acc: 71.827% (566/788) 0.7760251532445571\n",
      "\n",
      "Epoch: 20\n",
      "train: 110 111 Loss: 0.566 | Acc: 71.092% (3920/5514) 0.6537993026735022\n",
      "test: 15 32 Loss: 0.560 | Acc: 72.081% (568/788) 0.7971557281758613\n",
      "\n",
      "Epoch: 21\n",
      "train: 110 111 Loss: 0.542 | Acc: 72.960% (4023/5514) 0.6805604067946559\n",
      "test: 15 32 Loss: 0.526 | Acc: 73.731% (581/788) 0.8225996089621643\n",
      "\n",
      "Epoch: 22\n",
      "train: 110 111 Loss: 0.516 | Acc: 75.154% (4144/5514) 0.7088976941486753\n",
      "test: 15 32 Loss: 0.497 | Acc: 75.381% (594/788) 0.8543714331008245\n",
      "\n",
      "Epoch: 23\n",
      "train: 110 111 Loss: 0.490 | Acc: 76.732% (4231/5514) 0.7291971564435931\n",
      "test: 15 32 Loss: 0.470 | Acc: 76.523% (603/788) 0.8773845381526104\n",
      "\n",
      "Epoch: 24\n",
      "train: 110 111 Loss: 0.473 | Acc: 77.657% (4282/5514) 0.7418790257459953\n",
      "test: 15 32 Loss: 0.443 | Acc: 78.173% (616/788) 0.8875898330162757\n",
      "\n",
      "Epoch: 25\n",
      "train: 110 111 Loss: 0.459 | Acc: 78.582% (4333/5514) 0.7546501995789334\n",
      "test: 15 32 Loss: 0.428 | Acc: 80.584% (635/788) 0.890337666455295\n",
      "\n",
      "Epoch: 26\n",
      "train: 110 111 Loss: 0.438 | Acc: 79.797% (4400/5514) 0.768346134344895\n",
      "test: 15 32 Loss: 0.440 | Acc: 78.680% (620/788) 0.8901989537095752\n",
      "\n",
      "Epoch: 27\n",
      "train: 110 111 Loss: 0.453 | Acc: 78.945% (4353/5514) 0.7614323361689608\n",
      "test: 15 32 Loss: 0.625 | Acc: 69.036% (544/788) 0.8758917247939124\n",
      "\n",
      "Epoch: 28\n",
      "train: 110 111 Loss: 0.425 | Acc: 80.631% (4446/5514) 0.7771668346343\n",
      "test: 15 32 Loss: 0.442 | Acc: 80.711% (636/788) 0.8997503170577044\n",
      "\n",
      "Epoch: 29\n",
      "train: 110 111 Loss: 0.441 | Acc: 80.450% (4436/5514) 0.7798931266809804\n",
      "test: 15 32 Loss: 0.409 | Acc: 82.107% (647/788) 0.8970553265694357\n",
      "\n",
      "Epoch: 30\n",
      "train: 110 111 Loss: 0.416 | Acc: 81.756% (4508/5514) 0.7914668269140486\n",
      "test: 15 32 Loss: 0.441 | Acc: 80.964% (638/788) 0.9005495666878038\n",
      "\n",
      "Epoch: 31\n",
      "train: 110 111 Loss: 0.422 | Acc: 81.375% (4487/5514) 0.7896279464757052\n",
      "test: 15 32 Loss: 0.400 | Acc: 82.360% (649/788) 0.9046515007398013\n",
      "\n",
      "Epoch: 32\n",
      "train: 110 111 Loss: 0.403 | Acc: 81.828% (4512/5514) 0.7925910624526613\n",
      "test: 15 32 Loss: 0.424 | Acc: 81.980% (646/788) 0.9044137074614246\n",
      "\n",
      "Epoch: 33\n",
      "train: 110 111 Loss: 0.406 | Acc: 82.064% (4525/5514) 0.7970039164627059\n",
      "test: 15 32 Loss: 0.401 | Acc: 81.218% (640/788) 0.9081589515958571\n",
      "\n",
      "Epoch: 34\n",
      "train: 110 111 Loss: 0.402 | Acc: 81.792% (4510/5514) 0.7954225168437108\n",
      "test: 15 32 Loss: 0.421 | Acc: 79.315% (625/788) 0.9065670577045023\n",
      "\n",
      "Epoch: 35\n",
      "train: 110 111 Loss: 0.407 | Acc: 81.846% (4513/5514) 0.7948814732743673\n",
      "test: 15 32 Loss: 0.391 | Acc: 82.868% (653/788) 0.9065142147537519\n",
      "\n",
      "Epoch: 36\n",
      "train: 110 111 Loss: 0.388 | Acc: 82.898% (4571/5514) 0.8076107073628246\n",
      "test: 15 32 Loss: 0.445 | Acc: 78.807% (621/788) 0.9028680511519764\n",
      "\n",
      "Epoch: 37\n",
      "train: 110 111 Loss: 0.389 | Acc: 82.554% (4552/5514) 0.8032975906555746\n",
      "test: 15 32 Loss: 0.381 | Acc: 83.503% (658/788) 0.9125118896639188\n",
      "\n",
      "Epoch: 38\n",
      "train: 110 111 Loss: 0.375 | Acc: 83.442% (4601/5514) 0.8128275108031356\n",
      "test: 15 32 Loss: 0.424 | Acc: 80.964% (638/788) 0.9071879623758191\n",
      "\n",
      "Epoch: 39\n",
      "train: 110 111 Loss: 0.381 | Acc: 83.333% (4595/5514) 0.812748639044859\n",
      "test: 15 32 Loss: 0.404 | Acc: 82.614% (651/788) 0.9145925808497146\n",
      "\n",
      "Epoch: 40\n",
      "train: 110 111 Loss: 0.402 | Acc: 81.647% (4502/5514) 0.7955852680909488\n",
      "test: 15 32 Loss: 0.411 | Acc: 81.091% (639/788) 0.9112898964278165\n",
      "\n",
      "Epoch: 41\n",
      "train: 110 111 Loss: 0.389 | Acc: 82.789% (4565/5514) 0.8072639220129408\n",
      "test: 15 32 Loss: 0.400 | Acc: 82.234% (648/788) 0.9133904037201438\n",
      "\n",
      "Epoch: 42\n",
      "train: 110 111 Loss: 0.389 | Acc: 82.155% (4530/5514) 0.799793431109275\n",
      "test: 15 32 Loss: 0.370 | Acc: 84.645% (667/788) 0.9170828049038258\n",
      "\n",
      "Epoch: 43\n",
      "train: 110 111 Loss: 0.373 | Acc: 83.170% (4586/5514) 0.8110675021230692\n",
      "test: 15 32 Loss: 0.375 | Acc: 83.629% (659/788) 0.9154710949059395\n",
      "\n",
      "Epoch: 44\n",
      "train: 110 111 Loss: 0.370 | Acc: 83.515% (4605/5514) 0.8139517463417485\n",
      "test: 15 32 Loss: 0.371 | Acc: 84.518% (666/788) 0.9154248573240328\n",
      "\n",
      "Epoch: 45\n",
      "train: 110 111 Loss: 0.372 | Acc: 83.061% (4580/5514) 0.8115244575480065\n",
      "test: 15 32 Loss: 0.415 | Acc: 80.838% (637/788) 0.9134696681462693\n",
      "\n",
      "Epoch: 46\n",
      "train: 110 111 Loss: 0.362 | Acc: 83.678% (4614/5514) 0.8175082784047873\n",
      "test: 15 32 Loss: 0.402 | Acc: 82.234% (648/788) 0.9188530437539632\n",
      "\n",
      "Epoch: 47\n",
      "train: 110 111 Loss: 0.379 | Acc: 82.662% (4558/5514) 0.806591425513136\n",
      "test: 15 32 Loss: 0.355 | Acc: 85.660% (675/788) 0.9200948530965968\n",
      "\n",
      "Epoch: 48\n",
      "train: 110 111 Loss: 0.364 | Acc: 83.769% (4619/5514) 0.8191368341543924\n",
      "test: 15 32 Loss: 0.388 | Acc: 82.614% (651/788) 0.9188200169097441\n",
      "\n",
      "Epoch: 49\n",
      "train: 110 111 Loss: 0.359 | Acc: 84.313% (4649/5514) 0.8247108557168461\n",
      "test: 15 32 Loss: 0.365 | Acc: 84.391% (665/788) 0.9174262840837033\n",
      "\n",
      "Epoch: 50\n",
      "train: 110 111 Loss: 0.366 | Acc: 84.131% (4639/5514) 0.8228826167062068\n",
      "test: 15 32 Loss: 0.351 | Acc: 85.025% (670/788) 0.9213366624392307\n",
      "\n",
      "Epoch: 51\n",
      "train: 110 111 Loss: 0.361 | Acc: 84.022% (4633/5514) 0.822267917764716\n",
      "test: 15 32 Loss: 0.354 | Acc: 85.406% (673/788) 0.9195598182202493\n",
      "\n",
      "Epoch: 52\n",
      "train: 110 111 Loss: 0.369 | Acc: 83.605% (4610/5514) 0.8176343062936742\n",
      "test: 15 32 Loss: 0.363 | Acc: 85.152% (671/788) 0.919440921581061\n",
      "\n",
      "Epoch: 53\n",
      "train: 110 111 Loss: 0.363 | Acc: 83.968% (4630/5514) 0.8214693933760242\n",
      "test: 15 32 Loss: 0.351 | Acc: 85.279% (672/788) 0.9230210314943987\n",
      "\n",
      "Epoch: 54\n",
      "train: 110 111 Loss: 0.349 | Acc: 84.984% (4686/5514) 0.8322076372066043\n",
      "test: 15 32 Loss: 0.376 | Acc: 83.503% (658/788) 0.9178027901077995\n",
      "\n",
      "Epoch: 55\n",
      "train: 110 111 Loss: 0.354 | Acc: 84.675% (4669/5514) 0.8296175971656246\n",
      "test: 15 32 Loss: 0.387 | Acc: 83.249% (656/788) 0.9217065630944834\n",
      "\n",
      "Epoch: 56\n",
      "train: 110 111 Loss: 0.350 | Acc: 84.657% (4668/5514) 0.8291132769546321\n",
      "test: 15 32 Loss: 0.374 | Acc: 84.518% (666/788) 0.9185558021559924\n",
      "\n",
      "Epoch: 57\n",
      "train: 110 111 Loss: 0.359 | Acc: 83.769% (4619/5514) 0.820387097581892\n",
      "test: 15 32 Loss: 0.369 | Acc: 84.645% (667/788) 0.9214951912914817\n",
      "\n",
      "Epoch: 58\n",
      "train: 110 111 Loss: 0.365 | Acc: 83.896% (4626/5514) 0.8214168122038397\n",
      "test: 15 32 Loss: 0.355 | Acc: 84.772% (668/788) 0.9250224582540688\n",
      "\n",
      "Epoch: 59\n",
      "train: 110 111 Loss: 0.371 | Acc: 83.551% (4607/5514) 0.817550218149268\n",
      "test: 15 32 Loss: 0.354 | Acc: 85.025% (670/788) 0.9258217078841683\n",
      "\n",
      "Epoch: 60\n",
      "train: 110 111 Loss: 0.354 | Acc: 84.476% (4658/5514) 0.8271957334134571\n",
      "test: 15 32 Loss: 0.373 | Acc: 83.503% (658/788) 0.9256631790319171\n",
      "\n",
      "Epoch: 61\n",
      "train: 110 111 Loss: 0.356 | Acc: 84.784% (4675/5514) 0.8330007365537215\n",
      "test: 15 32 Loss: 0.343 | Acc: 86.168% (679/788) 0.9258217078841683\n",
      "\n",
      "Epoch: 62\n",
      "train: 110 111 Loss: 0.343 | Acc: 85.256% (4701/5514) 0.8357537364973845\n",
      "test: 15 32 Loss: 0.353 | Acc: 85.406% (673/788) 0.9264360071866413\n",
      "\n",
      "Epoch: 63\n",
      "train: 110 111 Loss: 0.346 | Acc: 85.056% (4690/5514) 0.8335997863368241\n",
      "test: 15 32 Loss: 0.342 | Acc: 86.041% (678/788) 0.9253064891143521\n",
      "\n",
      "Epoch: 64\n",
      "train: 110 111 Loss: 0.356 | Acc: 83.787% (4620/5514) 0.8204448951402059\n",
      "test: 15 32 Loss: 0.346 | Acc: 85.279% (672/788) 0.9266341682519552\n",
      "\n",
      "Epoch: 65\n",
      "train: 110 111 Loss: 0.339 | Acc: 85.274% (4702/5514) 0.8367045793610552\n",
      "test: 15 32 Loss: 0.385 | Acc: 83.122% (655/788) 0.922558655675333\n",
      "\n",
      "Epoch: 66\n",
      "train: 110 111 Loss: 0.350 | Acc: 85.056% (4690/5514) 0.8336890908673599\n",
      "test: 15 32 Loss: 0.344 | Acc: 86.675% (683/788) 0.9245204502219404\n",
      "\n",
      "Epoch: 67\n",
      "train: 110 111 Loss: 0.342 | Acc: 84.947% (4684/5514) 0.8339674372312257\n",
      "test: 15 32 Loss: 0.380 | Acc: 84.010% (662/788) 0.927063517226802\n",
      "\n",
      "Epoch: 68\n",
      "train: 110 111 Loss: 0.349 | Acc: 85.092% (4692/5514) 0.834876340350416\n",
      "test: 15 32 Loss: 0.345 | Acc: 85.787% (676/788) 0.9247252166560981\n",
      "\n",
      "Epoch: 69\n",
      "train: 110 111 Loss: 0.346 | Acc: 84.694% (4670/5514) 0.8298540037850098\n",
      "test: 15 32 Loss: 0.343 | Acc: 85.406% (673/788) 0.9278495561192137\n",
      "\n",
      "Epoch: 70\n",
      "train: 110 111 Loss: 0.345 | Acc: 84.766% (4674/5514) 0.8314247619763009\n",
      "test: 15 32 Loss: 0.339 | Acc: 86.421% (681/788) 0.9272748890298033\n",
      "\n",
      "Epoch: 71\n",
      "train: 110 111 Loss: 0.343 | Acc: 84.748% (4673/5514) 0.8309204417653085\n",
      "test: 15 32 Loss: 0.350 | Acc: 85.406% (673/788) 0.9253923589093216\n",
      "\n",
      "Epoch: 72\n",
      "train: 110 111 Loss: 0.335 | Acc: 85.999% (4742/5514) 0.8455357124227192\n",
      "test: 15 32 Loss: 0.344 | Acc: 85.660% (675/788) 0.9277636863242443\n",
      "\n",
      "Epoch: 73\n",
      "train: 110 111 Loss: 0.344 | Acc: 84.984% (4686/5514) 0.8333685961035682\n",
      "test: 15 32 Loss: 0.344 | Acc: 85.660% (675/788) 0.9272088353413656\n",
      "\n",
      "Epoch: 74\n",
      "train: 110 111 Loss: 0.341 | Acc: 85.727% (4727/5514) 0.8424361357846176\n",
      "test: 15 32 Loss: 0.372 | Acc: 83.503% (658/788) 0.9264624286620166\n",
      "\n",
      "Epoch: 75\n",
      "train: 110 111 Loss: 0.348 | Acc: 84.875% (4680/5514) 0.8329325062231486\n",
      "test: 15 32 Loss: 0.339 | Acc: 86.168% (679/788) 0.9281666138237159\n",
      "\n",
      "Epoch: 76\n",
      "train: 110 111 Loss: 0.338 | Acc: 85.491% (4714/5514) 0.839630763324215\n",
      "test: 15 32 Loss: 0.345 | Acc: 85.533% (674/788) 0.9301812513210737\n",
      "\n",
      "Epoch: 77\n",
      "train: 110 111 Loss: 0.337 | Acc: 85.310% (4704/5514) 0.8384276560273255\n",
      "test: 15 32 Loss: 0.372 | Acc: 84.264% (664/788) 0.9258018917776368\n",
      "\n",
      "Epoch: 78\n",
      "train: 110 111 Loss: 0.329 | Acc: 85.963% (4740/5514) 0.8447056810618059\n",
      "test: 15 32 Loss: 0.364 | Acc: 85.025% (670/788) 0.9289724688226592\n",
      "\n",
      "Epoch: 79\n",
      "train: 110 111 Loss: 0.333 | Acc: 85.709% (4726/5514) 0.8409494657377325\n",
      "test: 15 32 Loss: 0.342 | Acc: 86.294% (680/788) 0.9278891883322764\n",
      "\n",
      "Epoch: 80\n",
      "train: 110 111 Loss: 0.335 | Acc: 85.637% (4722/5514) 0.8425043661151903\n",
      "test: 15 32 Loss: 0.355 | Acc: 85.406% (673/788) 0.9290583386176284\n",
      "\n",
      "Epoch: 81\n",
      "train: 110 111 Loss: 0.330 | Acc: 85.727% (4727/5514) 0.8413644814181893\n",
      "test: 15 32 Loss: 0.442 | Acc: 79.949% (630/788) 0.9238467025998732\n",
      "\n",
      "Epoch: 82\n",
      "train: 110 111 Loss: 0.334 | Acc: 85.546% (4717/5514) 0.8402506786518356\n",
      "test: 15 32 Loss: 0.342 | Acc: 85.406% (673/788) 0.9274664447262735\n",
      "\n",
      "Epoch: 83\n",
      "train: 110 111 Loss: 0.346 | Acc: 84.748% (4673/5514) 0.8318134870706653\n",
      "test: 15 32 Loss: 0.335 | Acc: 86.421% (681/788) 0.9296396110758826\n",
      "\n",
      "Epoch: 84\n",
      "train: 110 111 Loss: 0.331 | Acc: 85.709% (4726/5514) 0.8422890336957679\n",
      "test: 15 32 Loss: 0.351 | Acc: 85.279% (672/788) 0.9280080849714649\n",
      "\n",
      "Epoch: 85\n",
      "train: 110 111 Loss: 0.323 | Acc: 86.072% (4746/5514) 0.8458562071865108\n",
      "test: 15 32 Loss: 0.337 | Acc: 85.914% (677/788) 0.9291243923060664\n",
      "\n",
      "Epoch: 86\n",
      "train: 110 111 Loss: 0.330 | Acc: 85.546% (4717/5514) 0.8406972013045139\n",
      "test: 15 32 Loss: 0.335 | Acc: 84.518% (666/788) 0.9291045761995351\n",
      "\n",
      "Epoch: 87\n",
      "train: 110 111 Loss: 0.335 | Acc: 85.872% (4735/5514) 0.8437022570259505\n",
      "test: 15 32 Loss: 0.343 | Acc: 85.914% (677/788) 0.9285299091101246\n",
      "\n",
      "Epoch: 88\n",
      "train: 110 111 Loss: 0.320 | Acc: 86.253% (4756/5514) 0.8479523597887572\n",
      "test: 15 32 Loss: 0.341 | Acc: 84.391% (665/788) 0.9282987212005918\n",
      "\n",
      "Epoch: 89\n",
      "train: 110 111 Loss: 0.328 | Acc: 85.383% (4708/5514) 0.8384802371995101\n",
      "test: 15 32 Loss: 0.345 | Acc: 86.041% (678/788) 0.9315881948848024\n",
      "\n",
      "Epoch: 90\n",
      "train: 110 111 Loss: 0.326 | Acc: 85.618% (4721/5514) 0.8411963051293769\n",
      "test: 15 32 Loss: 0.358 | Acc: 84.772% (668/788) 0.9309210526315789\n",
      "\n",
      "Epoch: 91\n",
      "train: 110 111 Loss: 0.330 | Acc: 86.108% (4748/5514) 0.8468648476084957\n",
      "test: 15 32 Loss: 0.353 | Acc: 85.025% (670/788) 0.9318656203762419\n",
      "\n",
      "Epoch: 92\n",
      "train: 110 111 Loss: 0.334 | Acc: 85.782% (4730/5514) 0.843859791887059\n",
      "test: 15 32 Loss: 0.352 | Acc: 85.533% (674/788) 0.9287941238638765\n",
      "\n",
      "Epoch: 93\n",
      "train: 110 111 Loss: 0.328 | Acc: 85.945% (4739/5514) 0.8450944061561703\n",
      "test: 15 32 Loss: 0.334 | Acc: 85.533% (674/788) 0.9306106002959205\n",
      "\n",
      "Epoch: 94\n",
      "train: 110 111 Loss: 0.323 | Acc: 86.543% (4772/5514) 0.8513776475767799\n",
      "test: 15 32 Loss: 0.354 | Acc: 86.041% (678/788) 0.9263831642358908\n",
      "\n",
      "Epoch: 95\n",
      "train: 110 111 Loss: 0.323 | Acc: 86.507% (4770/5514) 0.850190398093724\n",
      "test: 15 32 Loss: 0.340 | Acc: 86.294% (680/788) 0.9310927922215175\n",
      "\n",
      "Epoch: 96\n",
      "train: 110 111 Loss: 0.328 | Acc: 85.836% (4733/5514) 0.8434080528482512\n",
      "test: 15 32 Loss: 0.339 | Acc: 86.421% (681/788) 0.929950063411541\n",
      "\n",
      "Epoch: 97\n",
      "train: 110 111 Loss: 0.328 | Acc: 86.126% (4749/5514) 0.8476370814110951\n",
      "test: 15 32 Loss: 0.341 | Acc: 85.787% (676/788) 0.9304917036567323\n",
      "\n",
      "Epoch: 98\n",
      "train: 110 111 Loss: 0.317 | Acc: 86.779% (4785/5514) 0.8550760653425392\n",
      "test: 15 32 Loss: 0.333 | Acc: 86.421% (681/788) 0.9314825089833015\n",
      "\n",
      "Epoch: 99\n",
      "train: 110 111 Loss: 0.317 | Acc: 86.525% (4771/5514) 0.8513198500184659\n",
      "test: 15 32 Loss: 0.354 | Acc: 84.010% (662/788) 0.9256103360811667\n",
      "cost time: 40.47872635099999\n",
      "best roc_auc on validset: 91 0.9318656203762419\n",
      "test: 31 32 Loss: 0.343 | Acc: 85.279% (1344/1576) 0.9282645872509743\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "result_valid = []\n",
    "for epoch in range(100):\n",
    "    train(epoch, trainloader, 'LSTM')\n",
    "    result_valid.append(np.array(test(epoch,validloader)))\n",
    "result_valid = np.array(result_valid)\n",
    "end = time.process_time()\n",
    "print('cost time:', end-start)\n",
    "\n",
    "best_index = best_result(result_valid)\n",
    "net = torch.load('./LSTM/' + str(str(best_index)) +'.pt')\n",
    "torch.save(net, 'best_LSTM.pt')\n",
    "auc, result_lstm = test(best_index,testloader)\n",
    "result['LSTM'] = result_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-18T16:29:21.183923Z",
     "iopub.status.busy": "2021-06-18T16:29:21.183382Z",
     "iopub.status.idle": "2021-06-18T16:29:21.193904Z",
     "shell.execute_reply": "2021-06-18T16:29:21.194467Z",
     "shell.execute_reply.started": "2021-06-18T14:50:12.587894Z"
    },
    "papermill": {
     "duration": 0.088215,
     "end_time": "2021-06-18T16:29:21.194623",
     "exception": false,
     "start_time": "2021-06-18T16:29:21.106408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN : 0.92383765295833\n",
      "LSTM : 0.9282645872509743\n"
     ]
    }
   ],
   "source": [
    "for key, value in result.items():\n",
    "    print(key,':',roc_auc_score(value[0],value[1]))\n",
    "np.save('result.npy', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.072901,
     "end_time": "2021-06-18T16:29:21.340687",
     "exception": false,
     "start_time": "2021-06-18T16:29:21.267786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 101.784537,
   "end_time": "2021-06-18T16:29:22.560169",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-18T16:27:40.775632",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
