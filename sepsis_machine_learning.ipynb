{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 import required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:44:30.885468Z",
     "iopub.status.busy": "2021-06-09T09:44:30.885090Z",
     "iopub.status.idle": "2021-06-09T09:44:30.891722Z",
     "shell.execute_reply": "2021-06-09T09:44:30.890571Z",
     "shell.execute_reply.started": "2021-06-09T09:44:30.885431Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import joblib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:44:33.150401Z",
     "iopub.status.busy": "2021-06-09T09:44:33.150023Z",
     "iopub.status.idle": "2021-06-09T09:44:33.157777Z",
     "shell.execute_reply": "2021-06-09T09:44:33.156705Z",
     "shell.execute_reply.started": "2021-06-09T09:44:33.150368Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_label(data):\n",
    "    n = 0\n",
    "    for (i,_,_,_,j) in data:\n",
    "        n = n + j\n",
    "    print('the count of different state:\\n1->',n,'  0->',len(data)-n,'  total->',len(data))\n",
    "    return {'1':n, '0':len(data)-n, 'total':len(data)}\n",
    "\n",
    "def index_delete(data, index = None):\n",
    "    data_new = []\n",
    "    for i, sub in enumerate(data):\n",
    "        if not (sub[3][:,index] == 0).all():\n",
    "            sub[2] = sub[2][:, index]\n",
    "            sub[3] = sub[3][:, index]\n",
    "            data_new.append(sub)\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 get the index and features name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:49:26.247095Z",
     "iopub.status.busy": "2021-06-09T09:49:26.246705Z",
     "iopub.status.idle": "2021-06-09T09:49:26.260537Z",
     "shell.execute_reply": "2021-06-09T09:49:26.259266Z",
     "shell.execute_reply.started": "2021-06-09T09:49:26.247062Z"
    }
   },
   "outputs": [],
   "source": [
    "index = [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, \n",
    "         16, 19, 21, 22, 25, 27, 28, 29, 31, 32,\n",
    "         34, 35, 39, 40, 41, 42, 46, 48, 49, 50, \n",
    "         51, 53, 55, 56, 57, 58, 60, 61, 63, 64, \n",
    "         70, 73, 74, 75, 77, 78, 79, 80, 82, 83, \n",
    "         84, 85, 89, 91, 92, 98, 100, 102, 105, \n",
    "         106, 107, 110, 111, 115, 116, 117, 119, \n",
    "         120, 122, 124, 131, 133, 135, 136, 138, \n",
    "         140, 141, 144, 145, 146, 147, 150, 151, \n",
    "         152, 155, 157, 159, 160, 161, 162, 163, \n",
    "         164, 165, 166, 170, 171, 173]\n",
    "\n",
    "items = ['PLT', 'INR', 'D-Dimer', 'FIB', 'PT', 'HBA1c', 'HGB', \n",
    "         'Na', 'EO%', 'APOB', 'CK-MB', 'pO2', 'TBIL', 'Ca', \n",
    "         'TG', 'Cys-c', 'TP', 'CHOI', 'TCO2', 'gGlu', 'CO2CP', \n",
    "         'gHGB', 'PTA', 'NRBC%', 'ABE', 'MCV', 'CHE', 'Cl-', \n",
    "         'CaO2', 'PDW', 'α-HBDH', 'CRE', 'RDW-CV', 'WBC', \n",
    "         'P-LCR', 'GA%', 'K+', 'AMY', 'SOD', 'CK', 'TBA', \n",
    "         'MCH', 'UA', 'Mg', 'Lac', 'GLB', 'HDL', 'FCOHb', \n",
    "         'LDH', 'Glu', 'IG%', 'BUN', 'Cl', 'SpO2', 'PA-aDO2', \n",
    "         'FDP', 'p50', 'MetHb', 'APOA', 'DBIL', 'MCHC', 'ALB', \n",
    "         'RBC', 'eGFR', 'MPV', 'PA', 'Na+', 'pH', 'HCT', 'GGT', \n",
    "         'APOE', 'ALP', 'FO2Hb', 'AG', 'PCT', 'APTT', 'K', 'AB', \n",
    "         'LPS', 'proBNP', 'pCO2', 'ALT', 'A/G', 'LDL', 'Lp(a)', \n",
    "         'RDW-SD', 'MONO%', 'NEUT%', 'TnT', 'LYMPH%', 'BASO%', \n",
    "         'procalcitonin', 'P', 'HHb', 'AST', 'IDBIL', 'Ca2+', \n",
    "         'T', 'TT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:50:37.264092Z",
     "iopub.status.busy": "2021-06-09T09:50:37.263701Z",
     "iopub.status.idle": "2021-06-09T09:50:37.275022Z",
     "shell.execute_reply": "2021-06-09T09:50:37.273515Z",
     "shell.execute_reply.started": "2021-06-09T09:50:37.264058Z"
    }
   },
   "outputs": [],
   "source": [
    "index_mimic = [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 13, \n",
    "               16, 19, 21, 25, 27, 28, 29, 32, 35, \n",
    "               39, 40, 42, 50, 51, 53, 57, 58, 61, \n",
    "               64, 70, 73, 74, 75, 77, 78, 79, 80, \n",
    "               83, 84, 85, 89, 91, 98, 102, 105, \n",
    "               106, 107, 116, 117, 119,120, 124, \n",
    "               133, 136, 138, 140, 144, 145, 146, \n",
    "               150, 155, 157, 159,160, 161, 163, \n",
    "               165, 166, 170, 171, 173]\n",
    "\n",
    "items_mimic = ['PLT', 'INR', 'D-Dimer', 'FIB', 'PT', 'HBA1c', \n",
    "               'HGB', 'Na', 'EO%', 'CK-MB', 'pO2', 'TBIL', \n",
    "               'Ca', 'TG', 'TP', 'CHOI', 'TCO2', 'gGlu', \n",
    "               'gHGB', 'NRBC%', 'ABE', 'MCV', 'Cl-', 'CRE', \n",
    "               'RDW-CV', 'WBC', 'K+', 'AMY', 'CK', 'MCH', \n",
    "               'UA', 'Mg', 'Lac', 'GLB', 'HDL', 'FCOHb', \n",
    "               'LDH', 'Glu', 'BUN', 'Cl', 'SpO2', 'PA-aDO2', \n",
    "               'FDP', 'MetHb', 'DBIL', 'MCHC', 'ALB', 'RBC', \n",
    "               'Na+', 'pH', 'HCT', 'GGT', 'ALP', 'AG', 'APTT', \n",
    "               'K', 'AB', 'proBNP', 'pCO2', 'ALT', 'LDL', 'MONO%', \n",
    "               'NEUT%', 'TnT', 'LYMPH%', 'BASO%', 'P', 'AST', \n",
    "               'IDBIL', 'Ca2+', 'T', 'TT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:50:37.994923Z",
     "iopub.status.busy": "2021-06-09T09:50:37.994569Z",
     "iopub.status.idle": "2021-06-09T09:50:37.999968Z",
     "shell.execute_reply": "2021-06-09T09:50:37.998647Z",
     "shell.execute_reply.started": "2021-06-09T09:50:37.994893Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('model/'):\n",
    "    os.makedirs('model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 get the train, valid, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:50:47.130819Z",
     "iopub.status.busy": "2021-06-09T09:50:47.130314Z",
     "iopub.status.idle": "2021-06-09T09:50:49.330569Z",
     "shell.execute_reply": "2021-06-09T09:50:49.329563Z",
     "shell.execute_reply.started": "2021-06-09T09:50:47.130787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features count: 72\n",
      "shape for x and y: (7847, 216) (7847,) 7847\n",
      "the count of different state:\n",
      "1-> 3046.0   0-> 4801.0   total-> 7847\n"
     ]
    }
   ],
   "source": [
    "dic_name = '../input/sample-xjtu/dic_3_1.npy'\n",
    "# data = np.load(dic_name, allow_pickle=True)\n",
    "data = np.load(dic_name, allow_pickle=True)\n",
    "data = index_delete(data, index_mimic)\n",
    "feature_num = data[0][2].shape[1]\n",
    "print('features count:', feature_num)\n",
    "\n",
    "lackitem = []\n",
    "x = []\n",
    "y = []\n",
    "temp = []\n",
    "for i in data:\n",
    "    temp = np.array(i[2])\n",
    "    x.append(np.reshape(temp, -1))\n",
    "    y.append(np.array(i[4]))\n",
    "x = np.array(x)\n",
    "y = np.array(y).reshape(len(y))\n",
    "\n",
    "items_real = []\n",
    "time = [' at T1', ' at T2', ' at T3']\n",
    "for i in range(3):\n",
    "    for j in items_mimic:\n",
    "        items_real.append(j + time[i])\n",
    "data_pd = pd.DataFrame(np.hstack((x,y.reshape(-1,1))), columns = items_real + ['state'])\n",
    "data_pd.to_csv('model/data.csv', index = None)\n",
    "print('shape for x and y:', x.shape, y.shape, len(data))\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data_pd.iloc[:,:-1], data_pd.iloc[:,-1], test_size = 0.2, random_state = 42)\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train, y_train, test_size = 0.125, random_state = 42)\n",
    "check_label(data)\n",
    "result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 train and save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T03:16:54.036043Z",
     "iopub.status.busy": "2021-06-09T03:16:54.035645Z",
     "iopub.status.idle": "2021-06-09T03:16:54.404735Z",
     "shell.execute_reply": "2021-06-09T03:16:54.403757Z",
     "shell.execute_reply.started": "2021-06-09T03:16:54.036019Z"
    }
   },
   "outputs": [],
   "source": [
    "def LR_model(x_train, y_train, x_test, y_test):\n",
    "    model = LogisticRegression()  \n",
    "    model.fit(x_train,y_train)\n",
    "    pred_train = model.predict_proba(x_train)[:,-1]\n",
    "    pred_test = model.predict_proba(x_test)[:,-1]\n",
    "    result = [roc_auc_score(y_train,pred_train), roc_auc_score(y_test,pred_test)]\n",
    "    return model, result, (y_test.values, pred_test)\n",
    "\n",
    "print('running for LR:\\n')\n",
    "model_LR,auc_LR, result_LR = LR_model(x_train, y_train, x_test, y_test)\n",
    "result['LR'] = result_LR\n",
    "joblib.dump(model_LR, 'model/LR_99.model')\n",
    "print(auc_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T03:19:58.495636Z",
     "iopub.status.busy": "2021-06-09T03:19:58.495176Z",
     "iopub.status.idle": "2021-06-09T03:21:40.088387Z",
     "shell.execute_reply": "2021-06-09T03:21:40.087016Z",
     "shell.execute_reply.started": "2021-06-09T03:19:58.495607Z"
    }
   },
   "outputs": [],
   "source": [
    "def SVM_model(x_train, y_train, x_test, y_test):\n",
    "    model = SVC(kernel='rbf', probability=True)  \n",
    "    model.fit(x_train,y_train)  \n",
    "    pred_train = model.predict_proba(x_train)[:,-1]\n",
    "    pred_test = model.predict_proba(x_test)[:,-1]\n",
    "    result = [roc_auc_score(y_train,pred_train), roc_auc_score(y_test,pred_test)]\n",
    "    return model, result, (y_test.values, pred_test)\n",
    "\n",
    "print('running for SVM:\\n')\n",
    "model_SVM, auc_SVM, result_SVM = SVM_model(x_train, y_train, x_test, y_test)\n",
    "result['SVM'] = result_SVM\n",
    "joblib.dump(model_SVM, 'model/SVM_99.model')\n",
    "print(auc_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Xgooost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T09:51:07.458319Z",
     "iopub.status.busy": "2021-06-09T09:51:07.457894Z",
     "iopub.status.idle": "2021-06-09T09:51:23.838332Z",
     "shell.execute_reply": "2021-06-09T09:51:23.836826Z",
     "shell.execute_reply.started": "2021-06-09T09:51:07.458278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running for Xgboost:\n",
      "\n",
      "[09:51:07] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"scale_pos_weight\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalid-logloss:0.67674\n",
      "[1]\tvalid-logloss:0.66205\n",
      "[2]\tvalid-logloss:0.64942\n",
      "[3]\tvalid-logloss:0.63667\n",
      "[4]\tvalid-logloss:0.62485\n",
      "[5]\tvalid-logloss:0.61254\n",
      "[6]\tvalid-logloss:0.60057\n",
      "[7]\tvalid-logloss:0.58898\n",
      "[8]\tvalid-logloss:0.57773\n",
      "[9]\tvalid-logloss:0.56977\n",
      "[10]\tvalid-logloss:0.55867\n",
      "[11]\tvalid-logloss:0.54614\n",
      "[12]\tvalid-logloss:0.53736\n",
      "[13]\tvalid-logloss:0.52533\n",
      "[14]\tvalid-logloss:0.51764\n",
      "[15]\tvalid-logloss:0.50876\n",
      "[16]\tvalid-logloss:0.49947\n",
      "[17]\tvalid-logloss:0.48968\n",
      "[18]\tvalid-logloss:0.48233\n",
      "[19]\tvalid-logloss:0.47468\n",
      "[20]\tvalid-logloss:0.46612\n",
      "[21]\tvalid-logloss:0.45644\n",
      "[22]\tvalid-logloss:0.44852\n",
      "[23]\tvalid-logloss:0.44116\n",
      "[24]\tvalid-logloss:0.43231\n",
      "[25]\tvalid-logloss:0.42490\n",
      "[26]\tvalid-logloss:0.41679\n",
      "[27]\tvalid-logloss:0.40841\n",
      "[28]\tvalid-logloss:0.40090\n",
      "[29]\tvalid-logloss:0.39405\n",
      "[30]\tvalid-logloss:0.38822\n",
      "[31]\tvalid-logloss:0.38054\n",
      "[32]\tvalid-logloss:0.37447\n",
      "[33]\tvalid-logloss:0.36814\n",
      "[34]\tvalid-logloss:0.36283\n",
      "[35]\tvalid-logloss:0.35698\n",
      "[36]\tvalid-logloss:0.35096\n",
      "[37]\tvalid-logloss:0.34613\n",
      "[38]\tvalid-logloss:0.33944\n",
      "[39]\tvalid-logloss:0.33339\n",
      "[40]\tvalid-logloss:0.32833\n",
      "[41]\tvalid-logloss:0.32330\n",
      "[42]\tvalid-logloss:0.31972\n",
      "[43]\tvalid-logloss:0.31478\n",
      "[44]\tvalid-logloss:0.31011\n",
      "[45]\tvalid-logloss:0.30709\n",
      "[46]\tvalid-logloss:0.30467\n",
      "[47]\tvalid-logloss:0.30172\n",
      "[48]\tvalid-logloss:0.29987\n",
      "[49]\tvalid-logloss:0.29927\n",
      "[50]\tvalid-logloss:0.33829\n",
      "[51]\tvalid-logloss:0.37543\n",
      "[52]\tvalid-logloss:0.37419\n",
      "[53]\tvalid-logloss:0.37225\n",
      "[54]\tvalid-logloss:0.37192\n",
      "[55]\tvalid-logloss:0.41120\n",
      "[56]\tvalid-logloss:0.40835\n",
      "[57]\tvalid-logloss:0.40703\n",
      "[58]\tvalid-logloss:0.40675\n",
      "[59]\tvalid-logloss:0.44625\n",
      "[60]\tvalid-logloss:0.44474\n",
      "[61]\tvalid-logloss:0.44387\n",
      "[62]\tvalid-logloss:0.44303\n",
      "[63]\tvalid-logloss:0.44273\n",
      "[64]\tvalid-logloss:0.44323\n",
      "[65]\tvalid-logloss:0.48389\n",
      "[66]\tvalid-logloss:0.48666\n",
      "[67]\tvalid-logloss:0.48361\n",
      "[68]\tvalid-logloss:0.48362\n",
      "[69]\tvalid-logloss:0.48799\n",
      "[70]\tvalid-logloss:0.48827\n",
      "[71]\tvalid-logloss:0.56581\n",
      "[72]\tvalid-logloss:0.56666\n",
      "[73]\tvalid-logloss:0.56740\n",
      "[74]\tvalid-logloss:0.60826\n",
      "[75]\tvalid-logloss:0.60837\n",
      "[76]\tvalid-logloss:0.60908\n",
      "[77]\tvalid-logloss:0.60909\n",
      "[78]\tvalid-logloss:0.60913\n",
      "[79]\tvalid-logloss:0.61012\n",
      "[80]\tvalid-logloss:0.61079\n",
      "[81]\tvalid-logloss:0.61336\n",
      "[82]\tvalid-logloss:0.61394\n",
      "[83]\tvalid-logloss:0.61401\n",
      "[84]\tvalid-logloss:0.61290\n",
      "[85]\tvalid-logloss:0.61447\n",
      "[86]\tvalid-logloss:0.61710\n",
      "[87]\tvalid-logloss:0.65863\n",
      "[88]\tvalid-logloss:0.62204\n",
      "[89]\tvalid-logloss:0.69937\n",
      "[90]\tvalid-logloss:0.70154\n",
      "[91]\tvalid-logloss:0.70663\n",
      "[92]\tvalid-logloss:0.74740\n",
      "[93]\tvalid-logloss:0.71105\n",
      "[94]\tvalid-logloss:0.79332\n",
      "[95]\tvalid-logloss:0.83492\n",
      "[96]\tvalid-logloss:0.83610\n",
      "[97]\tvalid-logloss:0.83528\n",
      "[98]\tvalid-logloss:0.87730\n",
      "[99]\tvalid-logloss:0.87955\n",
      "[100]\tvalid-logloss:0.88306\n",
      "[101]\tvalid-logloss:0.92356\n",
      "[102]\tvalid-logloss:0.96322\n",
      "[103]\tvalid-logloss:1.00243\n",
      "[104]\tvalid-logloss:1.00310\n",
      "[105]\tvalid-logloss:1.00253\n",
      "[106]\tvalid-logloss:1.00369\n",
      "[107]\tvalid-logloss:1.00448\n",
      "[108]\tvalid-logloss:1.00379\n",
      "[109]\tvalid-logloss:1.00676\n",
      "[110]\tvalid-logloss:1.01041\n",
      "[111]\tvalid-logloss:1.09186\n",
      "[112]\tvalid-logloss:1.09473\n",
      "[113]\tvalid-logloss:1.09571\n",
      "[114]\tvalid-logloss:1.09738\n",
      "[115]\tvalid-logloss:1.09533\n",
      "[116]\tvalid-logloss:1.09694\n",
      "[117]\tvalid-logloss:1.13840\n",
      "[118]\tvalid-logloss:1.13839\n",
      "[119]\tvalid-logloss:1.14044\n",
      "[120]\tvalid-logloss:1.22441\n",
      "[121]\tvalid-logloss:1.18754\n",
      "[122]\tvalid-logloss:1.18824\n",
      "[123]\tvalid-logloss:1.26920\n",
      "[124]\tvalid-logloss:1.26952\n",
      "[125]\tvalid-logloss:1.23094\n",
      "[126]\tvalid-logloss:1.22840\n",
      "[127]\tvalid-logloss:1.23303\n",
      "[128]\tvalid-logloss:1.22971\n",
      "[129]\tvalid-logloss:1.27370\n",
      "[130]\tvalid-logloss:1.31503\n",
      "[131]\tvalid-logloss:1.31576\n",
      "[132]\tvalid-logloss:1.32032\n",
      "[133]\tvalid-logloss:1.36674\n",
      "[134]\tvalid-logloss:1.36368\n",
      "[135]\tvalid-logloss:1.36393\n",
      "[136]\tvalid-logloss:1.44396\n",
      "[137]\tvalid-logloss:1.40237\n",
      "[138]\tvalid-logloss:1.44539\n",
      "[139]\tvalid-logloss:1.44906\n",
      "[140]\tvalid-logloss:1.48602\n",
      "[141]\tvalid-logloss:1.48771\n",
      "[142]\tvalid-logloss:1.48809\n",
      "[143]\tvalid-logloss:1.49023\n",
      "[144]\tvalid-logloss:1.49578\n",
      "[145]\tvalid-logloss:1.49193\n",
      "[146]\tvalid-logloss:1.49819\n",
      "[147]\tvalid-logloss:1.53968\n",
      "[148]\tvalid-logloss:1.57875\n",
      "[149]\tvalid-logloss:1.62183\n",
      "[150]\tvalid-logloss:1.65830\n",
      "[151]\tvalid-logloss:1.61832\n",
      "[152]\tvalid-logloss:1.58165\n",
      "[153]\tvalid-logloss:1.57940\n",
      "[154]\tvalid-logloss:1.62231\n",
      "[155]\tvalid-logloss:1.70590\n",
      "[156]\tvalid-logloss:1.62750\n",
      "[157]\tvalid-logloss:1.66592\n",
      "[158]\tvalid-logloss:1.66348\n",
      "[159]\tvalid-logloss:1.66542\n",
      "[160]\tvalid-logloss:1.70664\n",
      "[161]\tvalid-logloss:1.74825\n",
      "[162]\tvalid-logloss:1.78811\n",
      "[163]\tvalid-logloss:1.78844\n",
      "[164]\tvalid-logloss:1.75019\n",
      "[165]\tvalid-logloss:1.74848\n",
      "[166]\tvalid-logloss:1.78890\n",
      "[167]\tvalid-logloss:1.78962\n",
      "[168]\tvalid-logloss:1.78995\n",
      "[169]\tvalid-logloss:1.79061\n",
      "[170]\tvalid-logloss:1.79152\n",
      "[171]\tvalid-logloss:1.75244\n",
      "[172]\tvalid-logloss:1.78989\n",
      "[173]\tvalid-logloss:1.79016\n",
      "[174]\tvalid-logloss:1.78986\n",
      "[175]\tvalid-logloss:1.79253\n",
      "[176]\tvalid-logloss:1.83335\n",
      "[177]\tvalid-logloss:1.80004\n",
      "[178]\tvalid-logloss:1.79546\n",
      "[179]\tvalid-logloss:1.79566\n",
      "[180]\tvalid-logloss:1.79753\n",
      "[181]\tvalid-logloss:1.91812\n",
      "[182]\tvalid-logloss:1.83963\n",
      "[183]\tvalid-logloss:1.87814\n",
      "[184]\tvalid-logloss:1.83812\n",
      "[185]\tvalid-logloss:1.87695\n",
      "[186]\tvalid-logloss:1.87849\n",
      "[187]\tvalid-logloss:1.92104\n",
      "[188]\tvalid-logloss:1.92037\n",
      "[189]\tvalid-logloss:1.92331\n",
      "[190]\tvalid-logloss:1.96093\n",
      "[191]\tvalid-logloss:1.96029\n",
      "[192]\tvalid-logloss:1.91965\n",
      "[193]\tvalid-logloss:1.92034\n",
      "[194]\tvalid-logloss:1.96114\n",
      "[195]\tvalid-logloss:1.96146\n",
      "[196]\tvalid-logloss:1.96187\n",
      "[197]\tvalid-logloss:1.96387\n",
      "[198]\tvalid-logloss:1.96314\n",
      "[199]\tvalid-logloss:1.96399\n",
      "[200]\tvalid-logloss:1.96494\n",
      "[201]\tvalid-logloss:1.96443\n",
      "[202]\tvalid-logloss:1.96613\n",
      "[203]\tvalid-logloss:1.96854\n",
      "[204]\tvalid-logloss:2.00726\n",
      "[205]\tvalid-logloss:2.00996\n",
      "[206]\tvalid-logloss:2.04689\n",
      "[207]\tvalid-logloss:2.01025\n",
      "[208]\tvalid-logloss:2.09129\n",
      "[209]\tvalid-logloss:2.09127\n",
      "[210]\tvalid-logloss:2.09196\n",
      "[211]\tvalid-logloss:2.05299\n",
      "[212]\tvalid-logloss:2.09120\n",
      "[213]\tvalid-logloss:2.09258\n",
      "[214]\tvalid-logloss:2.13194\n",
      "[215]\tvalid-logloss:2.13218\n",
      "[216]\tvalid-logloss:2.05852\n",
      "[217]\tvalid-logloss:2.09078\n",
      "[218]\tvalid-logloss:2.04955\n",
      "[219]\tvalid-logloss:2.01053\n",
      "[220]\tvalid-logloss:2.05042\n",
      "[221]\tvalid-logloss:2.05088\n",
      "[222]\tvalid-logloss:2.05885\n",
      "[223]\tvalid-logloss:2.13490\n",
      "[224]\tvalid-logloss:2.13295\n",
      "[225]\tvalid-logloss:2.13255\n",
      "[226]\tvalid-logloss:2.17131\n",
      "[227]\tvalid-logloss:2.17085\n",
      "[228]\tvalid-logloss:2.17104\n",
      "[229]\tvalid-logloss:2.17153\n",
      "[230]\tvalid-logloss:2.17136\n",
      "[231]\tvalid-logloss:2.17166\n",
      "[232]\tvalid-logloss:2.17137\n",
      "[233]\tvalid-logloss:2.17143\n",
      "[234]\tvalid-logloss:2.17244\n",
      "[235]\tvalid-logloss:2.17262\n",
      "[236]\tvalid-logloss:2.13383\n",
      "[237]\tvalid-logloss:2.17332\n",
      "[238]\tvalid-logloss:2.13410\n",
      "[239]\tvalid-logloss:2.17338\n",
      "[240]\tvalid-logloss:2.13590\n",
      "[241]\tvalid-logloss:2.13409\n",
      "[242]\tvalid-logloss:2.13301\n",
      "[243]\tvalid-logloss:2.13306\n",
      "[244]\tvalid-logloss:2.13333\n",
      "[245]\tvalid-logloss:2.17445\n",
      "[246]\tvalid-logloss:2.17407\n",
      "[247]\tvalid-logloss:2.17451\n",
      "[248]\tvalid-logloss:2.09509\n",
      "[0.9972216446816212, 0.9681942492401833]\n"
     ]
    }
   ],
   "source": [
    "def Xgboost_model(x_train, y_train, x_test, y_test):\n",
    "    xgb_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "    xgb_test = xgb.DMatrix(x_test)\n",
    "    params = {'booster': 'gbtree',\n",
    "            'objective': 'rank:pairwise',  # 二分类的问题\n",
    "            'gamma': 0.5,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "            'max_depth': 15,  # 构建树的深度，越大越容易过拟合\n",
    "            #'lambda': 0.5,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "            'subsample': 0.5,  # 随机采样训练样本\n",
    "            'colsample_bytree': 0.5,  # 生成树时进行的列采样\n",
    "            'min_child_weight': 1,\n",
    "            # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "            # ，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "            # 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "            'scale_pos_weight': 1,\n",
    "            'silent': 0,  # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "            'eta': 0.015,  # 如同学习率\n",
    "            'nthread': 8,  # cpu 线程数\n",
    "            'eval_metric': 'logloss'  # 评价方式\n",
    "            }\n",
    "\n",
    "    plst = list(params.items())\n",
    "    num_rounds = 500  # 迭代次数\n",
    "    watchlist = [(xgb_valid, 'valid')]\n",
    "    model = xgb.train(plst, xgb_train, num_rounds, watchlist, early_stopping_rounds=200)\n",
    "    # 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练\n",
    "    # model = xgb.train(plst, xgb_train, num_rounds)\n",
    "    pred_train = model.predict(xgb_train)\n",
    "    pred_test = model.predict(xgb_test)\n",
    "    result = [roc_auc_score(y_train,pred_train), roc_auc_score(y_test,pred_test)]\n",
    "    return model, result, (y_test.values, pred_test)\n",
    "\n",
    "print('running for Xgboost:\\n')\n",
    "model_Xgboost, auc_Xgboost, result_Xgboost = Xgboost_model(x_train, y_train, x_test, y_test)\n",
    "result['Xgboost'] = result_Xgboost\n",
    "joblib.dump(model_Xgboost, 'model/Xgboost_99.model')\n",
    "print(auc_Xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Lightgbm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T03:19:24.010969Z",
     "iopub.status.busy": "2021-06-09T03:19:24.01062Z",
     "iopub.status.idle": "2021-06-09T03:19:35.492647Z",
     "shell.execute_reply": "2021-06-09T03:19:35.491018Z",
     "shell.execute_reply.started": "2021-06-09T03:19:24.010941Z"
    }
   },
   "outputs": [],
   "source": [
    "def Lightgbm_model(x_train, y_train, x_test, y_test):\n",
    "    lgb_train = lgb.Dataset(x_train, label=y_train)\n",
    "    lgb_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        # 'metric': {'auc','binary_logloss'},\n",
    "        'metric': {'binary_logloss'},\n",
    "        'num_leaves': 30,\n",
    "        'max_depth': 15,\n",
    "        'max_bin': 50,\n",
    "        'min_data_in_leaf': 15,\n",
    "        'learning_rate': 0.015,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.5,\n",
    "        'bagging_freq': 5,\n",
    "        'scale_pos_weight': 50\n",
    "    }\n",
    "\n",
    "    MAX_ROUNDS = 500\n",
    "    # model = lgb.train(params, lgb_train, num_boost_round=MAX_ROUNDS)\n",
    "    model = lgb.train(params, lgb_train, valid_sets=lgb_valid, \n",
    "                      num_boost_round=MAX_ROUNDS,early_stopping_rounds=200)\n",
    "    # pred_train = model.predict(x_train, num_iteration = model.best_iteration)\n",
    "    # pred_test = model.predict(x_test, num_iteration = model.best_iteration)\n",
    "    pred_train = model.predict(x_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    result = [roc_auc_score(y_train,pred_train), roc_auc_score(y_test,pred_test)]\n",
    "    return model, result, (y_test.values, pred_test)\n",
    "print('running for Lightgbm:\\n')\n",
    "model_Lightgbm, auc_Lightgbm, result_Lightgbm = Lightgbm_model(x_train, y_train, x_test, y_test)\n",
    "joblib.dump(model_Lightgbm, 'model/Lightgbm_99.model')\n",
    "model_Lightgbm.save_model('model/Lightgbm_99.txt')\n",
    "result['Lightgbm'] = result_Lightgbm\n",
    "print(auc_Lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model/result.npy', result)\n",
    "model = ['LR', 'SVM', 'Xgboost', 'Lightgbm']\n",
    "auc = np.array([auc_LR, auc_SVM, auc_Xgboost, auc_Lightgbm])\n",
    "auc_pd = {'model': model, 'auc_train':auc[:,0], 'test_auc':auc[:,1]}\n",
    "auc_pd = pd.DataFrame(auc_pd)\n",
    "auc_pd.to_csv('model/auc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 plot features importance for Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T07:00:41.302858Z",
     "iopub.status.busy": "2021-06-08T07:00:41.302487Z",
     "iopub.status.idle": "2021-06-08T07:00:41.653177Z",
     "shell.execute_reply": "2021-06-08T07:00:41.652502Z",
     "shell.execute_reply.started": "2021-06-08T07:00:41.302826Z"
    }
   },
   "outputs": [],
   "source": [
    "importance_value = pd.DataFrame(model_Xgboost.get_fscore().items(), columns= ['features_names', 'F_score'])\n",
    "importance_value.to_csv('model/features_importance.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T07:00:44.253541Z",
     "iopub.status.busy": "2021-06-08T07:00:44.253096Z",
     "iopub.status.idle": "2021-06-08T07:00:45.236527Z",
     "shell.execute_reply": "2021-06-08T07:00:45.235542Z",
     "shell.execute_reply.started": "2021-06-08T07:00:44.253511Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,10))\n",
    "xgb.plot_importance(model_Xgboost, ax=ax, max_num_features=20, \n",
    "                    grid=False, xlabel='Features contributiton score')\n",
    "plt.savefig('model/features_importance.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-08T07:13:24.450887Z",
     "iopub.status.busy": "2021-06-08T07:13:24.450546Z",
     "iopub.status.idle": "2021-06-08T07:13:24.936493Z",
     "shell.execute_reply": "2021-06-08T07:13:24.935525Z",
     "shell.execute_reply.started": "2021-06-08T07:13:24.450857Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_bar(key_name,key_values,size=(5,8), N = 20):\n",
    "    norm = plt.Normalize(min(key_values),max(key_values))\n",
    "    norm_values = norm(key_values[-N:])\n",
    "    map_vir = cm.get_cmap(name='coolwarm')\n",
    "    colors = map_vir(norm_values)\n",
    "    fig,ax = plt.subplots(1,1, figsize=size) #调用figure创建一个绘图对象\n",
    "    plt.barh(key_name[-N:], key_values[-N:],height=0.5,color=colors,edgecolor='black') # edgecolor边框颜色  \n",
    "    # ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False) \n",
    "    ax.spines['top'].set_visible(False) \n",
    "    # ax.spines['bottom'].set_visible(False) \n",
    "    sm = cm.ScalarMappable(cmap=map_vir, norm = norm)  # norm设置最大最小值\n",
    "    plt.xlabel('Feature contributiton (%)')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature importance')\n",
    "    \n",
    "    position=fig.add_axes([0.9, 0.15, 0.035, 0.695])#位置[左,下,右,上]\n",
    "    cbar=plt.colorbar(sm,cax=position)\n",
    "    # cbar.ax.set_yticklabels(['1','2'])\n",
    "    plt.savefig('model/features_importance_colorbar.svg', bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "importance = pd.read_csv('model/features_importance.csv').values\n",
    "index_sorted = np.argsort(importance[:,1])\n",
    "importance_relative = importance[index_sorted,1]/sum(importance[index_sorted,1])*100\n",
    "draw_bar(importance[index_sorted,0], importance_relative.tolist(), N = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 shap explanation research for Xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model_Xgboost)\n",
    "shap_values = explainer.shap_values(x_train)\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('shap/'):\n",
    "    os.makedirs('shap/')\n",
    "y_base = explainer.expected_value\n",
    "print(y_base)\n",
    "xgb_train = xgb.DMatrix(x_train, label=y_train)\n",
    "y_pred = model_Xgboost.predict(xgb_train)\n",
    "print(y_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 9\n",
    "\n",
    "player_explainer = {}\n",
    "player_explainer['feature'] = x_train.columns\n",
    "player_explainer['feature_value'] = x_train.values[j]\n",
    "player_explainer['shap_value'] = shap_values[j]\n",
    "player_explainer = pd.DataFrame(player_explainer)\n",
    "player_explainer.to_csv('shap/negative_sample.csv', index = None)\n",
    "\n",
    "f = plt.gcf()\n",
    "features = [col + ' = ' + str(round(x_train.values[j, ind], 2)) \n",
    "            for ind, col in enumerate(x_train.columns)]\n",
    "t = shap.force_plot(explainer.expected_value, shap_values[j], \n",
    "                    feature_names=features,\n",
    "                    out_names='output value', \n",
    "                    text_rotation = 0, show = False, matplotlib=True)\n",
    "t.savefig('shap/base_value_negative.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 4996\n",
    "\n",
    "player_explainer = {}\n",
    "player_explainer['feature'] = x_train.columns\n",
    "player_explainer['feature_value'] = x_train.values[j]\n",
    "player_explainer['shap_value'] = shap_values[j]\n",
    "player_explainer = pd.DataFrame(player_explainer)\n",
    "player_explainer.to_csv('shap/postive_sample.csv', index = None)\n",
    "\n",
    "f = plt.gcf()\n",
    "features = [col + ' = ' + str(round(x_train.values[j, ind], 2)) \n",
    "            for ind, col in enumerate(x_train.columns)]\n",
    "t = shap.force_plot(explainer.expected_value, shap_values[j], \n",
    "                    feature_names=features,\n",
    "                    out_names='output value', \n",
    "                    text_rotation = 0, show = False, matplotlib=True)\n",
    "t.savefig('shap/base_value_postive.svg', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.gcf()\n",
    "shap.summary_plot(shap_values, x_train, show = False)\n",
    "# shap.summary_plot(shap_values, x_train, max_display=20, show = False)\n",
    "plt.savefig('shap/shap_value.svg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('PLT at T3', shap_values, x_train, interaction_index=None, show=False)\n",
    "plt.savefig('shap/shap_value_for_plt.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('PLT at T2', shap_values, x_train, interaction_index='D-Dimer at T2', show=False)\n",
    "plt.savefig('shap/shap_value_for_plt_and_D_Dimer.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('PLT at T2', shap_values, x_train, interaction_index='PCT at T2', show=False)\n",
    "plt.savefig('shap/shap_value_for_plt_and_pct.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
